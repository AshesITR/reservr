<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="reservr">
<title>Fitting Distributions and Neural Networks to Censored and Truncated Data: The R Package reservr • reservr</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Fitting Distributions and Neural Networks to Censored and Truncated Data: The R Package reservr">
<meta property="og:description" content="reservr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">reservr</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.3.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/distributions.html">Working with Distributions</a>
    <a class="dropdown-item" href="../articles/jss_paper.html">Fitting Distributions and Neural Networks to Censored and Truncated Data: The R Package reservr</a>
    <a class="dropdown-item" href="../articles/tensorflow.html">TensorFlow Integration</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/AshesITR/reservr/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">


<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Fitting Distributions and Neural Networks to Censored and Truncated Data: The R Package reservr</h1>
                        <h4 data-toc-skip class="author">Alexander Rosenstock</h4>
            <address class="author_afil">
      <div class="line-block">Heinrich-Heine-Universität Düsseldorf <br>
ARAG SE</div>
<br><small class="dont-index">Source: <a href="https://github.com/AshesITR/reservr/blob/HEAD/vignettes/jss_paper.Rmd" class="external-link"><code>vignettes/jss_paper.Rmd</code></a></small>
      <div class="d-none name"><code>jss_paper.Rmd</code></div>
    </address>
</div>

    
        <div class="abstract">
      <p class="abstract">Abstract</p>
      <p>Random truncation, i.e. truncated observations where the point of truncation varies by observation, and interval censoring arise naturally in various fields, such as insurance, operations research or medicine. This article presents the <em>R</em> package <strong>reservr</strong>, which implements distribution parameter estimation and distributional regression for randomly truncated and interval censored data based on (conditional) maximum likelihood. The package provides a flexible interface to specify (weighted) randomly truncated and interval censored observations, to specify distribution families to be estimated, and to compute (conditional) maximum-likelihood based parameter estimates. Distributional regression is supported via an interface to the <em>R</em> package <strong>tensorflow</strong> to build neural network models for distributional regression of censored and randomly truncated outcomes with arbitrary distribution families. The interface allows for arbitrary network architectures, including multi-modality and pre-initialization of network weights from a global parameter estimate to improve stability. Additional utilities for application in a general insurance context, as well as the usual random sampling, density, probability and quantile functions for distributions are provided.</p>
    </div>
    
<div class="section level2" number="1">
<h2 id="introduction">
<span class="header-section-number">1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Statistical analyses are typically concerned with modelling and estimating the distribution of some measured variable of interest <span class="math inline">\(Y\)</span>, called the outcome, possibly conditional on the value of one or several endogenous variables <span class="math inline">\(X\)</span>, called predictors.
In the absence of endogenous variables, this process is usually called distribution fitting, and in the presence of endogenous variables it is called regression.
Classical regression, such as via generalized linear models (GLMs), is concerned with the influence of endogenous variables on the mean of the outcome, i.e., <span class="math inline">\(\mathsf{E}(Y|X) = f(X)\)</span>, and often links other parameters of the conditional outcome distribution to its mean.
A gentle introduction to generalized linear models can be found in <span class="citation">Dobson and Barnett (<a href="#ref-DobsonBarnett2018">2018</a>)</span>.
An implementation of GLMs is available in the <strong>stats</strong> <em>R</em> package, which is part of <em>R</em> itself <span class="citation">(<a href="#ref-baseR">R Core Team 2023</a>)</span>.
Some models also allow specification of additional parameters of the conditional outcome distribution, such as Generalized Additive Models for Location, Scale and Shape <span class="citation">(<a href="#ref-GAMLSS">Stasinopoulos and Rigby 2007</a>)</span>.
More recently, deep distributional regression has been proposed, which allows for flexible specification of individual outcome distribution parameters <span class="citation">(<a href="#ref-deepregression">Rügamer et al. 2023</a>)</span>.</p>
<p>Statistical methods (such as those described and implemented in the previously mentioned papers) often require complete data, that is full information on all observations <span class="math inline">\((X, Y)\)</span> of interest.
In this paper, we describe an R-package that allows for distributional regression in three common observation schemes that do not provide complete data.
First of all, data with <em>interval censoring</em> applied to the outcome <span class="math inline">\(Y\)</span> refers to the case where only lower and upper bounds for <span class="math inline">\(Y\)</span> are observed, instead of the actual value.
Next, truncated data misses observations for which the outcome <span class="math inline">\(Y\)</span> falls out of a certain lower and upper truncation bound.
We consider the case of <em>random truncation</em>, where these truncation bounds are also random variables that may vary for each observation.
Finally, we consider a combination of the two, <em>randomly truncated interval censoring</em>.</p>
<p>The three scenarios can be combined into a single general scheme: instead of observing the real-valued target variable <span class="math inline">\(Y\)</span> (with <span class="math inline">\(\mu\)</span>-density <span class="math inline">\(f_\theta\)</span> and c.d.f. <span class="math inline">\(F_\theta\)</span>, where <span class="math inline">\(\mu\)</span> is a sigma-finite measure on <span class="math inline">\(\mathbb R\)</span> and <span class="math inline">\(\theta\)</span> is a parameter vector in some parameter space <span class="math inline">\(\Theta\)</span>), we observe the vector <span class="math inline">\((M, V, L, U)\)</span>, which satisfies <span class="math inline">\(L \le M \le V \le U\)</span> and <span class="math inline">\(L&lt;U\)</span>.
Its coordinates have the following interpretation: the last two coordinates, which satisfy <span class="math inline">\(-\infty \le L &lt; U \le \infty\)</span>, encode truncation: we only happen to observe <span class="math inline">\((M, V, L, U)\)</span> if <span class="math inline">\(L &lt; Y \le U\)</span>; in particular, a non-truncated observations means that <span class="math inline">\(L = -\infty\)</span> and <span class="math inline">\(U = \infty\)</span>.
The first two coordinates, which satisfy <span class="math inline">\(L \le M \le V \le U\)</span> and which may be <span class="math inline">\(\mp \infty\)</span>, encode censoring: the observation <span class="math inline">\((M, V) = (m, v)\)</span> means that the target variable <span class="math inline">\(Y\)</span> satisfies <span class="math inline">\(Y \in (m, v]\)</span> if <span class="math inline">\(m &lt; v\)</span> and <span class="math inline">\(Y = m\)</span> if <span class="math inline">\(m = v\)</span>; the latter corresponds to an uncensored observation of <span class="math inline">\(Y\)</span>.</p>
<p>It is instructive to focus on the simpler problem of distribution parameter estimation before proceeding with distributional regression.
Suppose we observe an independent sample <span class="math inline">\(\mathcal J = \{(m_i, v_i, l_i, u_i): i=1, \ldots, n\}\)</span> of <span class="math inline">\((M, V, L, U)\)</span>.
Suggested by standard maximum (conditional) likelihood approaches for truncated <span class="citation">(<a href="#ref-DoerreEmura2019">Dörre and Emura 2019</a>)</span> and censored observations <span class="citation">(<a href="#ref-Sun2006">Sun 2006</a>)</span>, we suggest to estimate <span class="math inline">\(\theta\)</span> by maximizing the objective function
<!-- -->
<span class="math display" id="eq:cml-likelihood-nw">\[\begin{align}
  \ell(\theta) = \sum_{(m, v, l, u) \in \mathcal J} \Big\{ \log f_\theta(m)  \mathbf{1}(m=v) + \log F_\theta((m,v]) \mathbf{1}(m&lt;v) \Big\} - \log F_\theta((l,u]), \tag{1.1}
\end{align}\]</span></p>
<p>where we use the notation <span class="math inline">\(F_\theta((l, u]) = F_\theta(u) - F_\theta(l)\)</span>.
A detailed motivation for this approach under suitable conditions ensuring that the censoring is non-informative is given in Section <a href="#motivation-cml-likelihood">1.1</a> below.
For later purposes, it is helpful to attach a weight <span class="math inline">\(w_i\)</span> to each observation <span class="math inline">\((m_i, v_i, l_i, u_i)\)</span>.
Denoting the resulting sample by <span class="math inline">\(\mathfrak{I} = \{(m_i, v_i, l_i, u_i, w_i)\}\)</span>, we aim at maximizing the weighted sum of the (conditional) log-likelihoods
<!-- -->
<span class="math display" id="eq:cml-likelihood">\[\begin{align}
  \ell(\theta) = \sum_{(m, v, l, u, w) \in \mathfrak{I}} w \cdot \Big[ \Big\{ \log f_\theta(m) \mathbf{1}(m = v) + \log F_\theta((m, v]) \mathbf{1}(m &lt; v) \Big\} - \log F_\theta((l, u]) \Big]. \tag{1.2}
\end{align}\]</span></p>
<p>A practical example of random truncation arises when modelling the reporting delay of claims in general insurance.
The target variable <span class="math inline">\(Y\)</span> is the reporting delay of an accident happening at accident time <span class="math inline">\(T_0\)</span>, which is hence reported to the insurer at calendar time <span class="math inline">\(Y+T_0\)</span>.
The truncation bounds <span class="math inline">\((L, U)\)</span> for <span class="math inline">\(Y\)</span> will be equal to <span class="math inline">\((0, \tau - T_0)\)</span> with <span class="math inline">\(\tau\)</span> the current calendar time.</p>
<p>Combined random truncation with interval censoring can occur when modelling failure times when only survival data at two (or more) maintenance appointments some time after purchase is captured, and only for items that are sold.
The target variable <span class="math inline">\(Y\)</span> is the failure time of an item.
Item condition (failed / functional) can be observed at maintenance times <span class="math inline">\(M_0\)</span> and <span class="math inline">\(M_1\)</span>, which may vary for each item.
For each maintained item, the production time <span class="math inline">\(P_0\)</span> and the purchase time <span class="math inline">\(P_1\)</span> is also known.
Only items that are functional at purchase time <span class="math inline">\(P_1\)</span> are observed at the maintenance times.
This gives rise to truncation bounds <span class="math inline">\((L, U) = (P_1 - P_0, \infty)\)</span> and censoring interval bounds <span class="math inline">\((M, V) \in \{ (P_1 - P_0, M_0 - P_0), (M_0 - P_0, M_1 - P_0), (M_1 - P_0, \infty) \}\)</span>, depending on the item condition at times <span class="math inline">\(M_0\)</span> and <span class="math inline">\(M_1\)</span>.</p>
<p>In the setting of distributional regression, weighted samples <span class="math inline">\(\mathfrak{I}\)</span> <span class="math inline">\((M, V, L, U, W)\)</span> have associated predictors <span class="math inline">\(X \in \mathfrak{X}\)</span>, resulting in observations of the shape <span class="math inline">\(\mathfrak{I}_{\text{reg}} = \{(m_i, v_i, l_i, u_i, w_i, x_i) : i = 1, \ldots, n\}\)</span>.
We are interested in estimating a regression function <span class="math inline">\(g : \mathfrak{X} \to \Theta\)</span> given a sample <span class="math inline">\(\mathfrak{I}_{\text{reg}}\)</span>, a parameterized family <span class="math inline">\(\mathcal{F} = \{F_\theta \mid \theta \in \Theta\}\)</span> and a family <span class="math inline">\(\mathcal{G}\)</span> of functions from <span class="math inline">\(\mathfrak{X}\)</span> to <span class="math inline">\(\Theta\)</span>.
It is assumed that there exists a fuction <span class="math inline">\(g \in \mathcal G\)</span> such that the conditional distribution of <span class="math inline">\(Y | X = x\)</span> is <span class="math inline">\(F_{g(x)}\)</span>.
Distributional regression can be formulated as the maximization problem
<!-- -->
<span class="math display" id="eq:cml-regression-likelihood">\[\begin{align}
  \hat g &amp; \in \mathop{\mathrm{arg\,max}}_{g \in \mathcal{G}} \ell(g | \mathfrak{I}_{\text{reg}}) \text{, where} \nonumber \\
  \ell(g | \mathfrak{I}_{\text{reg}}) &amp; := \sum_{(m, v, l, u, w, x) \in \mathfrak{I}_{\text{reg}}} w \cdot \begin{cases}
    \log f_{g(x)}(m) - \log F_{g(x)} ((l, u]) &amp; m = v \\
    \log F_{g(x)}((m, v]) - \log F_{g(x)}((l, u]) &amp; m &lt; v
  \end{cases}. \tag{1.3}
\end{align}\]</span></p>
<p>Compared to Equation <a href="#eq:cml-likelihood">(1.2)</a>, the global parameter <span class="math inline">\(\theta\)</span> is replaced by the regression function <span class="math inline">\(g\)</span> evaluated at the associated predictors <span class="math inline">\(x\)</span>.</p>
<div class="section level3" number="1.1" short-title="Motivation of the conditional likelihood">
<h3 id="motivation-cml-likelihood">
<span class="header-section-number">1.1</span> Motivation of Equation <a href="#eq:cml-likelihood-nw">(1.1)</a>.<a class="anchor" aria-label="anchor" href="#motivation-cml-likelihood"></a>
</h3>
<p>It is instructive to start by considering an untruncated, censored observation where <span class="math inline">\(l = -\infty, u = \infty\)</span> and <span class="math inline">\(m &lt; v\)</span>.
The only information we obtain from the observation <span class="math inline">\((m, v, l, u)\)</span> is then that <span class="math inline">\(Y \in (m, v]\)</span>.
For deriving the relevant likelihood contribution, we may follow the stochastic approach to interval censored observations described in : let <span class="math inline">\((C_1, C_2)\)</span> denote a random vector in <span class="math inline">\(\mathbb R^2\)</span> that is independent of the target variable <span class="math inline">\(Y\)</span> and which satisfies <span class="math inline">\(\mathsf{P}(C_1 &lt; C_2) = 1\)</span>.
Let
<!-- -->
<span class="math display">\[\begin{align*}
  D &amp; := \mathbf{1}(Y &gt; C_1) + \mathbf{1}(Y &gt; C_2),
\end{align*}\]</span></p>
<p>and define new random variables <span class="math inline">\((M, V) = f(Y,C_1,C_2)\)</span> by
<!-- -->
<span class="math display">\[\begin{align*}
  (M, V) &amp; := \begin{cases}
    (-\infty, C_1), &amp; D = 0, \\
    (C_1, C_2), &amp; D = 1, \\
    (C_2, \infty), &amp; D = 2.
  \end{cases}
\end{align*}\]</span></p>
<p>Note that <span class="math inline">\(D\)</span> can be reconstructed from <span class="math inline">\((M, V)\)</span>: we have <span class="math inline">\(D=0\)</span> if <span class="math inline">\(M=-\infty\)</span>, <span class="math inline">\(D=1\)</span> if <span class="math inline">\(-\infty&lt;M&lt;V&lt;\infty\)</span> and <span class="math inline">\(D=2\)</span> if <span class="math inline">\(V=\infty\)</span>.</p>
<p>It is instructive to proceed with the case where <span class="math inline">\((C_1, C_2)\)</span> and hence <span class="math inline">\((M, V)\)</span> is discrete.
Then, for <span class="math inline">\((m,v) \in \mathrm{supp}(M,V) \cap \mathbb R^2\)</span>, we have
<!-- -->
<span class="math display">\[\begin{align*}
  \mathsf{P}(M = m, V = v) &amp; = \mathsf{P}(M = m, V = v, D = 1) \\
  &amp; = \mathsf{P}(C_1 = m, C_2 = v, Y \in (m,  v]) \\
  &amp; = F_\theta((m, v]) \cdot \mathsf{P}(C_1 = m, C_2 = v).
\end{align*}\]</span></p>
<p>Likewise, for <span class="math inline">\((m,v) \in \mathrm{supp}(M, V) \cap (\{-\infty\} \times \mathbb R)\)</span>, we obtain
<!-- -->
<span class="math display">\[\begin{align*}
  \mathsf{P}(M = -\infty, V = v) &amp; = \mathsf{P}(M = -\infty, V = v, D = 0) \\
  &amp; = \mathsf{P}(C_1 = v, Y \le v) \\
  &amp; = F_\theta((-\infty, v]) \cdot \mathsf{P}(C_1 = v)
\end{align*}\]</span></p>
<p>and finally, for <span class="math inline">\((m,v) \in \mathrm{supp}(M,V) \cap (\mathbb R \times \{\infty\})\)</span>,
<!-- -->
<span class="math display">\[\begin{align*}
  \mathsf{P}(M = m, V = \infty) &amp; = \mathsf{P}(M=m, V=\infty, D=2) \\
  &amp; = \mathsf{P}(C_2 = m, Y &gt; m) \\
  &amp; = F_\theta((m, \infty]) \cdot \mathsf{P}(C_2 = m).
\end{align*}\]</span></p>
<p>If we assume that the distribution of the censoring variable <span class="math inline">\((C_1,C_2)\)</span> is non-informative, i.e., its distribution does not depend on <span class="math inline">\(\theta\)</span>, the likelihood of observing <span class="math inline">\((M, V) = (m, v)\)</span> is equal to <span class="math inline">\(F_\theta((m, v])\)</span>, up to a factor that does not depend on <span class="math inline">\(\theta\)</span>.
A similar argumentation can be used in the non-discrete case.
Overall, noting that <span class="math inline">\(F_\infty((-\infty, \infty]) = 1\)</span>, we have motivated the likelihood contribution <span class="math inline">\(F_\theta((m, v]) \cdot \mathbf{1}(m &lt; v)\)</span> for a censored, untruncated observation in <a href="#eq:cml-likelihood-nw">(1.1)</a>.</p>
<p>Next, consider an uncensored, truncated observation <span class="math inline">\((m, v, l, u)\)</span> where <span class="math inline">\(y = m = v\)</span>; we may hence identify such an observation with <span class="math inline">\((y, l, u)\)</span>.
We may then proceed as in and assume that <span class="math inline">\((L, U)\)</span> is independent of <span class="math inline">\(Y\)</span> and satisfies <span class="math inline">\(L \le U\)</span>, with <span class="math inline">\(L\)</span> possibly equal to <span class="math inline">\(-\infty\)</span> and <span class="math inline">\(U\)</span> possibly equal to <span class="math inline">\(\infty\)</span>.
Further, <span class="math inline">\((L, U)\)</span> shall have a density <span class="math inline">\(f_{(L, U)}\)</span> with respect to some dominating sigma-finite measure <span class="math inline">\(\nu\)</span>.
Truncation means that we only happen to observe <span class="math inline">\((Y, L, U)\)</span> if <span class="math inline">\(L &lt; Y \le U\)</span>. As a consequence, any observed value with <span class="math inline">\(M = V\)</span> can be regarded as being drawn from the <span class="math inline">\((\mu \otimes \nu)\)</span>-density
<!-- -->
<span class="math display" id="eq:trunc-dens">\[\begin{align}
  f_{(Y, L, U) | L &lt; Y \le U}(y, l, u) = \frac{f_{(L, U)}(l, u) f_\theta(y)}{\mathsf{P}(L &lt; Y \le U)} \mathbf{1}(l &lt; y \le u). \tag{1.4}
\end{align}\]</span></p>
<p>Subsequently, we write <span class="math inline">\((Y^{(t)}, L^{(t)}, U^{(t)})\)</span> for a random vector following the above density, i.e.,
<!-- -->
<span class="math display">\[\begin{align*}
  f_{(Y^{(t)}, L^{(t)}, U^{(t)})}(y, l, u) = f_{(Y, L, U) | L &lt; Y \le U}(y, l, u).
\end{align*}\]</span></p>
<p>Conditioning this density on <span class="math inline">\((L^{(t)}, U^{(t)}) = (l, u)\)</span>, we arrive at an expression that does not involve the nuisance density <span class="math inline">\(f_{(L,U)}\)</span>:</p>
<p><span class="math display">\[\begin{align*}
  f_{Y^{(t)} | L^{(t)} = l, U^{(t)} = u}(y) &amp; = \frac{f_{(Y^{(t)}, L^{(t)}, U^{(t)})}(y, l, u)}{f_{(L^{(t)}, U^{(t)})}(l, u)} \\
    &amp; = \frac{f_{(Y, L, U) | L &lt; Y \le U}(y, l, u)}{\int_{(l, u]} f_{(Y, L, U) | L &lt; Y \le U}(z, l, u) \,\mathrm{d}\mu(z)} = \frac{f_\theta(y)}{\int_{(l, u]} f_\theta(z) \,\mathrm{d}\mu(z)}.
\end{align*}\]</span></p>
<p>Overall, we arrive at the (conditional) log-likelihood contribution <span class="math inline">\(\log f_\theta(y) - \log F_\theta((l, u])\)</span> for an uncensored, truncated observation in <a href="#eq:cml-likelihood-nw">(1.1)</a>.</p>
<p>Finally, truncation and censoring can occur at the same time, i.e., we have <span class="math inline">\(l \le m &lt; v \le u\)</span> with either <span class="math inline">\(l \ne -\infty\)</span> or <span class="math inline">\(u \ne \infty\)</span>.
In accordance with the previous two cases, we make the assumption that <span class="math inline">\(Y, (C_1, C_2)\)</span> and <span class="math inline">\((L, U)\)</span> are mutually independent and satisfy <span class="math inline">\(C_1 &lt; C_2\)</span> and <span class="math inline">\(L &lt; U\)</span>.
Define
<!-- -->
<span class="math display">\[\begin{align*}
  D = \mathbf{1}(Y &gt; C_1) + \mathbf{1}(Y &gt; C_2)
\end{align*}\]</span>
<!-- -->
and
<!-- -->
<span class="math display">\[\begin{align*}
  (M, V) := \begin{cases}
    (L, \min(U, C_1)), &amp; D = 0, \\
    (\max(L, C_1), \min(C_2, U)), &amp; D = 1, \\
    (\max(L,C_2), U), &amp; D = 2.
  \end{cases}
\end{align*}\]</span></p>
<p>For simplicity, assume that all random variables are discrete.
For any observation <span class="math inline">\((m, v, l, u)\)</span>, one of the following four cases is met
<!-- -->
<span class="math display">\[\begin{align*}
  l &lt; m &lt; v &lt; u, \quad l = m &lt; v &lt; u, \quad l &lt; m &lt; v = u, \quad l = m &lt; v = u.
\end{align*}\]</span></p>
<p>In case <span class="math inline">\(l &lt; m &lt; v &lt; u\)</span>, we have
<span class="math display">\[\begin{align*}
  \mathsf{P}(M = m, V = v | L = l, U = u, L &lt; Y \le U) &amp; = \frac{\mathsf{P}(C_1 = m, C_2 = v, Y \in (m, v], L = l, U = u)}{\mathsf{P}(L = l, U = u, l &lt; Y \le u)} \\
  &amp; = \frac{\mathsf{P}(C_1 = m, C_2 = v) F_\theta((m, v])}{F_\theta((l, u])}
\end{align*}\]</span></p>
<p>by the independence assumption.
The factor in front does not depend on <span class="math inline">\(\theta\)</span> and is irrelevant for the (conditional) likelihood contribution.
Likewise, in case <span class="math inline">\(l = m &lt; v &lt; u\)</span>, we have
<!-- -->
<span class="math display">\[\begin{align*}
  \mathsf{P}(M = l, V = v | L = l, U = u, L &lt; Y \le U) &amp; = \frac{\mathsf{P}(M = l, V = v, L = l, U = u, l &lt; Y \le u)}{\mathsf{P}(L = l, U = u, l &lt; Y \le u)}.
\end{align*}\]</span></p>
<p>By definition of <span class="math inline">\((M,V)\)</span>, the event in the numerator is the disjoint union of the following two sets:
<!-- -->
<span class="math display">\[\begin{align*}
  &amp; \{D = 0, C_1 = v, L = l, U = u, l &lt; Y \le u\} = \{C_1 = v, L = l, U = u, Y \in (l, v]\} \\
  &amp; \{D = 1, C_1 \le l, C_2 = v, L = l, U = u, l &lt; Y \le u\} = \{C_1 \le l, C_2 = v, L = l, U = u, Y \in (l, v]\}.
\end{align*}\]</span></p>
<p>By independence, we obtain that
<!-- -->
<span class="math display">\[\begin{align*}
  \mathsf{P}(M = l, V = v | L = l, U = u, L &lt; Y \le U) = \{\mathsf{P}(C_1 = v) + \mathsf{P}(C_1 \le l, C_2 = v)\} \frac{F_\theta((l, v])}{F_\theta((l, u])}.
\end{align*}\]</span></p>
<p>Again, the factor in front of the fraction is independent of <span class="math inline">\(\theta\)</span> and is irrelevant for the likelihood.
The two cases <span class="math inline">\(l &lt; m &lt; v = u\)</span> and <span class="math inline">\(l = m &lt; v = u\)</span> can be treated similarly; in all cases, the likelihood contribution is equal to <span class="math inline">\(F_\theta((m, v]) /F_\theta((l, u])\)</span> times a factor that does not depend on <span class="math inline">\(\theta\)</span>.</p>
</div>
<div class="section level3" number="1.2">
<h3 id="related-packages">
<span class="header-section-number">1.2</span> Related packages<a class="anchor" aria-label="anchor" href="#related-packages"></a>
</h3>
<p>For the less general cases of non-informative censoring without random truncation and fixed truncation, i.e., <span class="math inline">\((L, U)\)</span> constant for all observations, as well as for estimation of distribution parameters in the absence of censoring or random truncation, there are a number of <em>R</em> packages that can fit distributions, some of them also supporting weights.
Among these are <strong>MASS</strong> <span class="citation">(<a href="#ref-MASS">Venables and Ripley 2002</a>)</span>, <strong>fitdistrplus</strong> <span class="citation">(<a href="#ref-fitdistrplus">Delignette-Muller and Dutang 2015</a>)</span>, <strong>survival</strong> <span class="citation">(<a href="#ref-survival">Therneau 2023</a>)</span>, <strong>flexsurv</strong> <span class="citation">(<a href="#ref-flexsurv">Jackson 2016</a>)</span>.
Note that fixed truncation is an operation that can be baked into the distribution family whose parameters are to be estimated, allowing for classical maximum likelihood estimation.
Many of the packages also support classic regression of expected values given predictors.
Distributional regression packages, such as <strong>gamlss</strong> <span class="citation">(<a href="#ref-GAMLSS">Stasinopoulos and Rigby 2007</a>)</span> and <strong>deepregression</strong> <span class="citation">(<a href="#ref-deepregression">Rügamer et al. 2023</a>)</span> currently do not support interval censoring or random truncation.
See the following table for an overview of available features for each package.</p>
<table class="table">
<colgroup>
<col width="26%">
<col width="19%">
<col width="13%">
<col width="22%">
<col width="19%">
</colgroup>
<thead><tr class="header">
<th>Package</th>
<th>sample weights</th>
<th>censoring</th>
<th>random truncation</th>
<th>regression</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><strong>MASS</strong></td>
<td>no</td>
<td>no</td>
<td>no</td>
<td>classic</td>
</tr>
<tr class="even">
<td><strong>fitdistrplus</strong></td>
<td>only integer</td>
<td>supported</td>
<td>no</td>
<td>no</td>
</tr>
<tr class="odd">
<td><strong>survival</strong></td>
<td>supported</td>
<td>supported</td>
<td>no</td>
<td>classic</td>
</tr>
<tr class="even">
<td><strong>flexsurv</strong></td>
<td>supported</td>
<td>supported</td>
<td>no</td>
<td>classic</td>
</tr>
<tr class="odd">
<td><strong>gamlss</strong></td>
<td>supported</td>
<td>no</td>
<td>no</td>
<td>distributional</td>
</tr>
<tr class="even">
<td><strong>deepregression</strong></td>
<td>supported</td>
<td>no</td>
<td>no</td>
<td>distributional</td>
</tr>
<tr class="odd">
<td><strong>reservr</strong></td>
<td>supported</td>
<td>supported</td>
<td>supported</td>
<td>distributional</td>
</tr>
</tbody>
</table>
<p>Another R6-based interface is provided by <strong>ROOPSD</strong> <span class="citation">(<a href="#ref-ROOPSD">Robin 2022</a>)</span>.</p>
<p><strong>reservr</strong> builds upon the <em>R</em> packages <strong>tensorflow</strong> <span class="citation">(<a href="#ref-tensorflowR">Allaire and Tang 2022</a>)</span> and <strong>keras</strong> <span class="citation">(<a href="#ref-kerasR">Chollet, Allaire, et al. 2017</a>)</span> as an interface to the machine learning library <strong>TensorFlow</strong> <span class="citation">(<a href="#ref-tensorflow">Abadi et al. 2015</a>)</span> to perform distributional regression.
This underlying infrastructure is shared with the distributional regression package <strong>deepregression</strong> <span class="citation">(<a href="#ref-deepregression">Rügamer et al. 2023</a>)</span>.
The latter also supports distributional regression, but at the time of writing requires complete samples and does not support truncation or censoring.</p>
<p>The remaining parts of this paper are structured as follows: Section <a href="#pkg-overview">2</a> details the core functionality of the corresponding <em>R</em> package <strong>reservr</strong>.
It is split into definition of samples <span class="math inline">\(\mathfrak{I}\)</span> (Section <a href="#trunc-obs">2.1</a>), definition of distribution families (Section <a href="#distributions">2.2</a>), mathematical definitions of some available distribution families (Section <a href="#dist-definitions">2.3</a>), estimation of distribution parameters (Section <a href="#fit-dist">2.4</a>) and distributional regression using <strong>tensorflow</strong> (Section <a href="#tensorflow">2.5</a>).
A conclusion is given in Section <a href="#conclusion">3</a>.</p>
</div>
</div>
<div class="section level2" number="2" short-title="Usage of reservr">
<h2 id="pkg-overview">
<span class="header-section-number">2</span> Usage of <strong>reservr</strong><a class="anchor" aria-label="anchor" href="#pkg-overview"></a>
</h2>
<p>The package serves two main goals: fitting distributions to randomly truncated non-informatively interval censored data and performing (deep) distributional regression with randomly truncated non-informatively interval censored data.
Four main components are integrated with each other to facilitate the analysis goals</p>
<ol style="list-style-type: decimal">
<li>Methods for representing a randomly truncated non-informatively interval censored sample <span class="math inline">\(\mathfrak{I}\)</span>.</li>
<li>Methods for specifying a parametrized distribution family <span class="math inline">\(\mathcal{F} = \{F_\theta | \theta \in \Theta\}\)</span> to be fitted.</li>
<li>Methods for estimating distribution parameters <span class="math inline">\(\theta\)</span> given a sample <span class="math inline">\(\mathfrak{I}\)</span>.</li>
<li>Methods for regression of distribution parameters given a regression sample <span class="math inline">\(\mathfrak{I}_{\text{reg}}\)</span>, a parametrized family <span class="math inline">\(\mathcal{F}\)</span> and a general <strong>tensorflow</strong> network <span class="math inline">\(\mathcal{G} : \mathfrak{X} \to \Theta\)</span> that processes <span class="math inline">\(X\)</span> to estimate the conditional distribution of <span class="math inline">\(Y | X = x\)</span> by <span class="math inline">\(F_{g(x)}\)</span> with <span class="math inline">\(g \in \mathcal G\)</span>.</li>
</ol>
<p>Each of these components is described one by one in the following sections.</p>
<div class="section level3" number="2.1">
<h3 id="trunc-obs">
<span class="header-section-number">2.1</span> Working with samples<a class="anchor" aria-label="anchor" href="#trunc-obs"></a>
</h3>
<p>A sample <span class="math inline">\(\mathfrak{I} = \{(m, v, l, u, w)_i\}\)</span> is represented as a tibble (from package <strong>tibble</strong>).
The core function to create this tibble is <code><a href="../reference/trunc_obs.html">trunc_obs()</a></code>.
A tibble created by <code><a href="../reference/trunc_obs.html">trunc_obs()</a></code> consists of five columns:</p>
<ul>
<li>
<code>x</code>: If observed, the exact value of the random variable, referred to as <span class="math inline">\(Y\)</span> in Section <a href="#introduction">1</a>. Otherwise <code>NA</code>.</li>
<li>
<code>xmin</code>: Lower interval censoring bound (<span class="math inline">\(M\)</span> in Section <a href="#introduction">1</a>) for the observation. If the observation is not censored, <code>xmin</code> is equal to <code>x</code>.</li>
<li>
<code>xmax</code>: Upper interval censoring bound (<span class="math inline">\(V\)</span> in Section <a href="#introduction">1</a>) for the observation. If the observation is not censored, <code>xmax</code> is equal to <code>x</code>.</li>
<li>
<code>tmin</code>: Lower truncation bound (<span class="math inline">\(L\)</span> in Section <a href="#introduction">1</a>). Only observations with <span class="math inline">\(\mathtt{x} \ge \mathtt{tmin}\)</span> are observed. Can be <span class="math inline">\(-\infty\)</span> to indicate no lower truncation.</li>
<li>
<code>tmax</code>: Upper truncation bound (<span class="math inline">\(U\)</span> in Section <a href="#introduction">1</a>). Only observations with <span class="math inline">\(\mathtt{x} \le \mathtt{tmax}\)</span> are observed. Can be <span class="math inline">\(\infty\)</span> to indicate no upper truncation.</li>
<li>
<code>w</code>: The weight associated with the observation. Defaults to <span class="math inline">\(1\)</span>.</li>
</ul>
<p>Note that, unlike in Section <a href="#introduction">1</a>, the lower bounds of intervals in <code>trunc_obs</code> are included, that is, we allow for <span class="math inline">\(\mathtt{x} \ge \mathtt{tmin}\)</span> rather than <span class="math inline">\(\mathtt{x} &gt; \mathtt{tmin}\)</span>, and that the unknown variable of interest is called <span class="math inline">\(\mathtt{x}\)</span> instead of <span class="math inline">\(Y\)</span>.
For continuous random variables, the formulas are equivalent to the half-open formulation.
For discrete random variables, <span class="math inline">\(\mathtt{xmin}\)</span> and <span class="math inline">\(\mathtt{tmin}\)</span> may have to be appropriately shifted, e.g., by replacing <span class="math inline">\(\mathtt{xmin}\)</span> by <span class="math inline">\(\mathtt{xmin}-0.5\)</span> for integer valued variables.
The following code defines a sample of size 1 without truncation and censoring, with the realized value of <span class="math inline">\(1.3\)</span>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/trunc_obs.html">trunc_obs</a></span><span class="op">(</span><span class="fl">1.3</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## <span style="color: #949494;"># A data frame: 1 × 6</span></span></span>
<span><span class="co">##       x  xmin  xmax  tmin  tmax     w</span></span>
<span><span class="co">##   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">## <span style="color: #BCBCBC;">1</span>   1.3   1.3   1.3  -<span style="color: #BB0000;">Inf</span>   <span style="color: #BB0000;">Inf</span>     1</span></span></code></pre>
<p>Simulating randomly truncated and interval censored data from a standard normal distribution with <span class="math inline">\(80\%\)</span> of the observations randomly interval censored and random uniform truncation <span class="math inline">\(L \sim \mathrm{Unif}[-2, 0]\)</span> and <span class="math inline">\(U \sim \mathrm{Unif}[0, 2]\)</span> can be simulated as follows</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">1000L</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">)</span></span>
<span><span class="va">is_censored</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">N</span>, size <span class="op">=</span> <span class="fl">1L</span>, prob <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span> <span class="op">==</span> <span class="fl">1L</span></span>
<span></span>
<span><span class="va">c_lower</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">is_censored</span><span class="op">)</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">2.0</span>, max <span class="op">=</span> <span class="fl">0.0</span><span class="op">)</span></span>
<span><span class="va">c_upper</span> <span class="op">&lt;-</span> <span class="va">c_lower</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">is_censored</span><span class="op">)</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">1.0</span><span class="op">)</span></span>
<span></span>
<span><span class="va">x_lower</span> <span class="op">&lt;-</span> <span class="va">x</span></span>
<span><span class="va">x_upper</span> <span class="op">&lt;-</span> <span class="va">x</span></span>
<span></span>
<span><span class="va">x_lower</span><span class="op">[</span><span class="va">is_censored</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/case_when.html" class="external-link">case_when</a></span><span class="op">(</span></span>
<span>  <span class="va">x</span><span class="op">[</span><span class="va">is_censored</span><span class="op">]</span> <span class="op">&lt;=</span> <span class="va">c_lower</span> <span class="op">~</span> <span class="op">-</span><span class="cn">Inf</span>,</span>
<span>  <span class="va">x</span><span class="op">[</span><span class="va">is_censored</span><span class="op">]</span> <span class="op">&lt;=</span> <span class="va">c_upper</span> <span class="op">~</span> <span class="va">c_lower</span>,</span>
<span>  <span class="cn">TRUE</span> <span class="op">~</span> <span class="va">c_upper</span></span>
<span><span class="op">)</span></span>
<span><span class="va">x_upper</span><span class="op">[</span><span class="va">is_censored</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/case_when.html" class="external-link">case_when</a></span><span class="op">(</span></span>
<span>  <span class="va">x</span><span class="op">[</span><span class="va">is_censored</span><span class="op">]</span> <span class="op">&lt;=</span> <span class="va">c_lower</span> <span class="op">~</span> <span class="va">c_lower</span>,</span>
<span>  <span class="va">x</span><span class="op">[</span><span class="va">is_censored</span><span class="op">]</span> <span class="op">&lt;=</span> <span class="va">c_upper</span> <span class="op">~</span> <span class="va">c_upper</span>,</span>
<span>  <span class="cn">TRUE</span> <span class="op">~</span> <span class="cn">Inf</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">t_lower</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">N</span>, min <span class="op">=</span> <span class="op">-</span><span class="fl">2.0</span>, max <span class="op">=</span> <span class="fl">0.0</span><span class="op">)</span></span>
<span><span class="va">t_upper</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="va">N</span>, min <span class="op">=</span> <span class="fl">0.0</span>, max <span class="op">=</span> <span class="fl">2.0</span><span class="op">)</span></span>
<span></span>
<span><span class="va">is_observed</span> <span class="op">&lt;-</span> <span class="va">t_lower</span> <span class="op">&lt;=</span> <span class="va">x</span> <span class="op">&amp;</span> <span class="va">x</span> <span class="op">&lt;=</span> <span class="va">t_upper</span></span>
<span></span>
<span><span class="va">obs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/trunc_obs.html">trunc_obs</a></span><span class="op">(</span></span>
<span>  xmin <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmax</a></span><span class="op">(</span><span class="va">x_lower</span>, <span class="va">t_lower</span><span class="op">)</span><span class="op">[</span><span class="va">is_observed</span><span class="op">]</span>,</span>
<span>  xmax <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">pmin</a></span><span class="op">(</span><span class="va">x_upper</span>, <span class="va">t_upper</span><span class="op">)</span><span class="op">[</span><span class="va">is_observed</span><span class="op">]</span>,</span>
<span>  tmin <span class="op">=</span> <span class="va">t_lower</span><span class="op">[</span><span class="va">is_observed</span><span class="op">]</span>,</span>
<span>  tmax <span class="op">=</span> <span class="va">t_upper</span><span class="op">[</span><span class="va">is_observed</span><span class="op">]</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Observations look like:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">obs</span><span class="op">[</span><span class="fl">8L</span><span class="op">:</span><span class="fl">12L</span>, <span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">## <span style="color: #949494;"># A tibble: 5 × 6</span></span></span>
<span><span class="co">##        x    xmin   xmax   tmin  tmax     w</span></span>
<span><span class="co">##    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">## <span style="color: #BCBCBC;">1</span> <span style="color: #BB0000;">NA</span>     -<span style="color: #BB0000;">0.479</span>   1.15  -<span style="color: #BB0000;">1.93</span>  1.15      1</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">2</span> <span style="color: #BB0000;">NA</span>     -<span style="color: #BB0000;">0.177</span>   1.79  -<span style="color: #BB0000;">0.210</span> 1.79      1</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">3</span> -<span style="color: #BB0000;">0.556</span> -<span style="color: #BB0000;">0.556</span>  -<span style="color: #BB0000;">0.556</span> -<span style="color: #BB0000;">0.957</span> 0.791     1</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">4</span> <span style="color: #BB0000;">NA</span>     -<span style="color: #BB0000;">0.379</span>   0.616 -<span style="color: #BB0000;">0.379</span> 0.616     1</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">5</span> <span style="color: #BB0000;">NA</span>      0.057<span style="text-decoration: underline;">5</span>  1.45  -<span style="color: #BB0000;">0.437</span> 1.45      1</span></span></code></pre>
<p>The total number of observations is smaller than the base population of <span class="math inline">\(1000\)</span> due to truncation:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">obs</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 623</span></span></code></pre>
<p>The total number of censored observations is roughly <span class="math inline">\(0.8 \cdot \mathtt{nrow(obs)}\)</span>.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="va">obs</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 496</span></span></code></pre>
<p>In addition to the <code><a href="../reference/trunc_obs.html">trunc_obs()</a></code> constructor function, there are functions <code><a href="../reference/trunc_obs.html">as_trunc_obs()</a></code> for coercion, <code><a href="../reference/trunc_obs.html">truncate_obs()</a></code> for artificially changing truncation bounds, and <code><a href="../reference/trunc_obs.html">repdel_obs()</a></code> for computing randomly truncated reporting delay observations from general insurance claims data containing accident date, reporting delay and evaluation date information.
The latter takes inputs of the form <span class="math inline">\((T_\text{acc}, D, \tau)\)</span> where <span class="math inline">\(T_{\text{acc}} &lt; \tau\)</span> are accident dates with corresponding reporting delays <span class="math inline">\(D \ge 0\)</span> and <span class="math inline">\(\tau\)</span> is the calendar date of observation.
It returns the sample <span class="math inline">\((\mathtt{xmin} = \mathtt{xmax} = D, \mathtt{tmin} = 0, \mathtt{tmax} = \tau - T_{\text{acc}}, \mathtt{w} = 1)\)</span> suitable for estimating the reporting delay distribution where a claim is only observed if it has been reported by the evaluation date, i.e., <span class="math inline">\(T_{\text{acc}} + D \le \tau\)</span>.
Such an analysis was performed using <strong>reservr</strong> in .</p>
</div>
<div class="section level3" number="2.2">
<h3 id="distributions">
<span class="header-section-number">2.2</span> Definition of distribution families<a class="anchor" aria-label="anchor" href="#distributions"></a>
</h3>
<p>Distribution families are implemented using the <strong>R6</strong> class system <span class="citation">(<a href="#ref-R6">Chang 2021</a>)</span>.
They inherit from the class <code>Distribution</code> and feature a common interface to</p>
<ul>
<li>manage fixed and free parameters of the underlying familiy,</li>
<li>use basic distribution functions for random number generation and computation of the density, cumulative distribution, hazard and quantile function,</li>
<li>use additional functions supporting parameter estimation procedures such as computing support or presence of a point mass,</li>
<li>compile performance enhanced functions to speed up basic functions for repeated evaluation,</li>
<li>provide <strong>tensorflow</strong>-specific implementations to support (deep) distributional regression.</li>
</ul>
<p>A <code>Distribution</code> object represents a distribution family <span class="math inline">\(\mathcal{F}\)</span> supported on a subset of the real line and parameterized by a fixed finite-dimensional parameter space <span class="math inline">\(\Theta\)</span>. The family may be a singleton, in which case it is rather a distribution than a distribution family.</p>
<p><strong>reservr</strong> provides a set of basic distribution families, optionally with some fixed parameters, as well as transformations of distribution families that take one or more underlying distribution families.
At the time of writing, these are:</p>
<table class="table">
<colgroup>
<col width="39%">
<col width="60%">
</colgroup>
<thead><tr class="header">
<th>Generator function         </th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>dist_bdegp(n, m, u, epsilon)</code></td>
<td>A Blended Dirac Erlang Generalized Pareto distribution family, see Section <a href="#dist-bdegp">2.3.4</a>
</td>
</tr>
<tr class="even">
<td><code>dist_beta(shape1, shape2, ncp)</code></td>
<td>A (non-central) Beta distribution family</td>
</tr>
<tr class="odd">
<td><code>dist_binomial(size, prob)</code></td>
<td>A Binomial distribution family</td>
</tr>
<tr class="even">
<td><code>dist_dirac(point)</code></td>
<td>A Dirac distribution family with full mass at <code>point</code>
</td>
</tr>
<tr class="odd">
<td><code>dist_discrete(size, probs)</code></td>
<td>A discrete distribution family with fixed support <span class="math inline">\(\{1, \ldots, \text{size}\}\)</span> and <span class="math inline">\(P(X = k) = \text{probs}_k\)</span>
</td>
</tr>
<tr class="even">
<td><code>dist_erlangmix(shapes, scale, probs)</code></td>
<td>An Erlang mixture distribution family, see Section <a href="#dist-erlangmix">2.3.2</a>
</td>
</tr>
<tr class="odd">
<td><code>dist_exponential(rate)</code></td>
<td>An Exponential distribution family</td>
</tr>
<tr class="even">
<td><code>dist_gamma(shape, rate)</code></td>
<td>A Gamma distribution family</td>
</tr>
<tr class="odd">
<td><code>dist_genpareto(u, sigmau, xi)</code></td>
<td>A Generalized Pareto Distribution family</td>
</tr>
<tr class="even">
<td><code>dist_genpareto1(u, sigmau, xi)</code></td>
<td>A Generalized Pareto Distribution family with the tail index <span class="math inline">\(\xi\)</span> constrained to <span class="math inline">\((0, 1)\)</span>
</td>
</tr>
<tr class="odd">
<td><code>dist_lognormal(meanlog, sdlog)</code></td>
<td>A Log-Normaldistribution family</td>
</tr>
<tr class="even">
<td><code>dist_negbinomial(size, mu)</code></td>
<td>A negative Binomial distribution family</td>
</tr>
<tr class="odd">
<td><code>dist_normal(mean, sd)</code></td>
<td>A Normal distribution family</td>
</tr>
<tr class="even">
<td><code>dist_pareto(shape, scale)</code></td>
<td>A Pareto Type I distribution family, i.e., a Generalized Pareto distribution family with <code>u</code> = <span class="math inline">\(0\)</span>
</td>
</tr>
<tr class="odd">
<td><code>dist_poisson(lambda)</code></td>
<td>A Poisson distribution family</td>
</tr>
<tr class="even">
<td><code>dist_uniform(min, max)</code></td>
<td>A uniform distribution family</td>
</tr>
<tr class="odd">
<td><code>dist_weibull(shape, scale)</code></td>
<td>A Weibull distribution family</td>
</tr>
</tbody>
</table>
<!-- Markdown tables hack --><table class="table">
<colgroup>
<col width="33%">
<col width="66%">
</colgroup>
<thead><tr class="header">
<th>Transformation function        </th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>dist_blended(dists, probs, breaks, bandwidths)</code></td>
<td>A Blended mixture distribution family, see Section <a href="#dist-blended">2.3.3</a>
</td>
</tr>
<tr class="even">
<td><code>dist_mixture(dists, probs)</code></td>
<td>A general Mixture distribution family, see Section <a href="#dist-mixture">2.3.1</a>
</td>
</tr>
<tr class="odd">
<td><code>dist_translate(dist, offset, multiplier)</code></td>
<td>The affine transformation family consisting of all distributions of <span class="math inline">\(\mathtt{multiplier} \cdot X + \mathtt{offset}\)</span> with <span class="math inline">\(X \sim F \in \mathtt{dist}\)</span>
</td>
</tr>
<tr class="even">
<td><code>dist_trunc(dist, min, max)</code></td>
<td>The truncated distribution family consisting of all distributions of <span class="math inline">\(X |(\mathtt{min} \le X  \le \mathtt{max})\)</span> with <span class="math inline">\(X \sim F \in \mathtt{dist}\)</span>
</td>
</tr>
</tbody>
</table>
<div class="section level4" number="2.2.1">
<h4 id="parameters">
<span class="header-section-number">2.2.1</span> Parameters<a class="anchor" aria-label="anchor" href="#parameters"></a>
</h4>
<p>Parameters of distribution families can either be fixed to a constant value, or free.
Free parameters (<em>placeholders</em>) are those that should be estimated from data whereas fixed parameters are held constant.
Most <code>Distribution</code> methods have an argument <code>with_params</code> to provide values for the free parameters and need fully specified parameters to work.
For example, generating samples from a distribution is only possible if it is fully parameterized using fixed parameters and the <code>with_params</code> argument of <code>Distribution$sample()</code>.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_normal.html">dist_normal</a></span><span class="op">(</span>sd <span class="op">=</span> <span class="fl">1.0</span><span class="op">)</span></span></code></pre></div>
<p>We have now defined <code>dist</code> to be a normal distribution family with standard deviation <span class="math inline">\(1\)</span> and free mean.
Since not all parameters required for a normal distribution are fixed, <code>dist$sample()</code> will error if not provided with a <code>mean</code> parameter.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dist</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="fl">1L</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Error in (function (n, mean = 0, sd = 1) : invalid arguments</span></span></code></pre>
<p>The <code>with_params</code> argument can be used both to provide free parameters and to override fixed parameters, if necessary.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">10L</span><span class="op">)</span></span>
<span><span class="va">dist</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="fl">1L</span>, with_params <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">0.0</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.01874617</span></span></code></pre>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">10L</span><span class="op">)</span></span>
<span><span class="va">dist</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="fl">1L</span>, with_params <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">0.0</span>, sd <span class="op">=</span> <span class="fl">2.0</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.03749234</span></span></code></pre>
<p>The two observations were drawn from a standard normal and a normal distribution with mean zero and standard deviation <span class="math inline">\(2\)</span>, respectively.
Since the chosen seed was identical, the second sample is exactly double the first sample.
Whenever the output length is greater than one, such as when taking more than one sample, <code>with_params</code> can optionally contain individual parameters for each entry.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">10L</span><span class="op">)</span></span>
<span><span class="va">dist</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="fl">3L</span>, with_params <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">0.0</span><span class="op">:</span><span class="fl">2.0</span>, sd <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.009373085 0.907873729 1.314334725</span></span></code></pre>
<p>The three observations were drawn from <span class="math inline">\(\mathcal{N}(\mu = 0, \sigma = 0.5)\)</span>, <span class="math inline">\(\mathcal{N}(\mu = 1, \sigma = 0.5)\)</span> and <span class="math inline">\(\mathcal{N}(\mu = 2, \sigma = 0.5)\)</span>, respectively.</p>
<p><code>Distribution</code>s have a set of fields and methods related to managing parameters:</p>
<ul>
<li>The active binding <code>default_params</code> gets or sets the list of all parameters and their fixed values, <code>NULL</code> represents a free parameter.
Component families are included as <code>Distribution</code> objects.</li>
<li>
<code>get_params()</code> gets the list of all parameters and their fixed values, traversing component distribution families.</li>
<li>
<code>get_placeholders()</code> gets the list of free parameters with <code>NULL</code> as values.</li>
<li>The active binding <code>param_bounds</code> gets or sets the domain of all regular family parameters as an <code>Interval</code> object.
Setting a bound via the <code>param_bounds</code> active binding allows restricting the natural parameter space of a family.</li>
<li>
<code>get_param_bounds()</code> returns the bounds of all free parameters as a list of <code>Interval</code>s, traversing component distribution families.</li>
<li>
<code>get_param_constraint()</code> returns <code>NULL</code> or a function that evaluates constraints on the parameter set.
The function must return a vector of constraint values (that need to be equal to <span class="math inline">\(0\)</span> for valid parameters) or a list with elements <code>constraints</code> and <code>jacobian</code>.
When returning a list, the <code>jacobian</code> element should contain the jacobian of the constraint function.
Used in <code>nloptr::slsqp(heq=)</code> for estimation.
An example is that mixture families require the <code>probs</code> parameters to sum to <span class="math inline">\(1\)</span> in addition to the box constraint that each parameter is in <span class="math inline">\([0, 1]\)</span>.
Note that box constraints are handled by <code>param_bounds</code> and need not be specified as a constraint function.</li>
<li>
<code>get_components()</code> returns a list of component families for transformations or mixtures.
The list is empty for basic families.</li>
</ul>
<p>Here is an example for a normal family with fixed standard deviation <span class="math inline">\(\sigma = 1\)</span> and a mixture distribution family with two components, one of which is specified as a normal distribution family:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_normal.html">dist_normal</a></span><span class="op">(</span>sd <span class="op">=</span> <span class="fl">1.0</span><span class="op">)</span></span>
<span><span class="va">mix</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_mixture.html">dist_mixture</a></span><span class="op">(</span>dists <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="../reference/dist_normal.html">dist_normal</a></span><span class="op">(</span><span class="op">)</span>, <span class="cn">NULL</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">dist</span><span class="op">$</span><span class="va">default_params</span></span></code></pre></div>
<pre><code><span><span class="co">## $mean</span></span>
<span><span class="co">## NULL</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $sd</span></span>
<span><span class="co">## [1] 1</span></span></code></pre>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mix</span><span class="op">$</span><span class="va">default_params</span></span></code></pre></div>
<pre><code><span><span class="co">## $dists</span></span>
<span><span class="co">## $dists[[1]]</span></span>
<span><span class="co">## A NormalDistribution with 2 dof</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $dists[[2]]</span></span>
<span><span class="co">## NULL</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $probs</span></span>
<span><span class="co">## $probs[[1]]</span></span>
<span><span class="co">## NULL</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $probs[[2]]</span></span>
<span><span class="co">## NULL</span></span></code></pre>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">dist</span><span class="op">$</span><span class="fu">get_placeholders</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 1</span></span>
<span><span class="co">##  $ mean: NULL</span></span></code></pre>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">mix</span><span class="op">$</span><span class="fu">get_placeholders</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 2</span></span>
<span><span class="co">##  $ dists:List of 2</span></span>
<span><span class="co">##   ..$ :List of 2</span></span>
<span><span class="co">##   .. ..$ mean: NULL</span></span>
<span><span class="co">##   .. ..$ sd  : NULL</span></span>
<span><span class="co">##   ..$ : NULL</span></span>
<span><span class="co">##  $ probs:List of 2</span></span>
<span><span class="co">##   ..$ : NULL</span></span>
<span><span class="co">##   ..$ : NULL</span></span></code></pre>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">dist</span><span class="op">$</span><span class="va">param_bounds</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 2</span></span>
<span><span class="co">##  $ mean:Classes 'Interval', 'R6' (-Inf, Inf) </span></span>
<span><span class="co">##  $ sd  :Classes 'Interval', 'R6' (0, Inf)</span></span></code></pre>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">mix</span><span class="op">$</span><span class="va">param_bounds</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 2</span></span>
<span><span class="co">##  $ dists:List of 1</span></span>
<span><span class="co">##   ..$ : NULL</span></span>
<span><span class="co">##  $ probs:List of 1</span></span>
<span><span class="co">##   ..$ :Classes 'Interval', 'R6' [0, 1]</span></span></code></pre>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">dist</span><span class="op">$</span><span class="fu">get_param_bounds</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 1</span></span>
<span><span class="co">##  $ mean:Classes 'Interval', 'R6' (-Inf, Inf)</span></span></code></pre>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">mix</span><span class="op">$</span><span class="fu">get_param_bounds</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 2</span></span>
<span><span class="co">##  $ dists:List of 1</span></span>
<span><span class="co">##   ..$ :List of 2</span></span>
<span><span class="co">##   .. ..$ mean:Classes 'Interval', 'R6' (-Inf, Inf) </span></span>
<span><span class="co">##   .. ..$ sd  :Classes 'Interval', 'R6' (0, Inf) </span></span>
<span><span class="co">##  $ probs:List of 2</span></span>
<span><span class="co">##   ..$ :Classes 'Interval', 'R6' [0, 1] </span></span>
<span><span class="co">##   ..$ :Classes 'Interval', 'R6' [0, 1]</span></span></code></pre>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">dist</span><span class="op">$</span><span class="fu">get_param_constraints</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##  NULL</span></span></code></pre>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">mix</span><span class="op">$</span><span class="fu">get_param_constraints</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## function (params)</span></span></code></pre>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dist</span><span class="op">$</span><span class="fu">get_components</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## list()</span></span></code></pre>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">mix</span><span class="op">$</span><span class="fu">get_components</span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">## A NormalDistribution with 2 dof</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">## NULL</span></span></code></pre>
</div>
<div class="section level4" number="2.2.2">
<h4 id="basic-distribution-functions">
<span class="header-section-number">2.2.2</span> Basic distribution functions<a class="anchor" aria-label="anchor" href="#basic-distribution-functions"></a>
</h4>
<p>The basic distribution functions (density, probability, hazard and quantile function, as well as random number generation) are provided by each distribution family.
In general, the argument <code>with_params</code> can be used to both specify missing parameters (placeholders) and to override fixed distribution parameters.
If the provided parameters are vectors of length greater than 1, they must conform to the input dimension (e.g. <code>length(x)</code> for <code>density</code>).
In this case, the parameters are “vectorized” in the sense that the <span class="math inline">\(i\)</span>th output element will be computed using the <span class="math inline">\(i\)</span>th entry from the parameter list.</p>
<ul>
<li>
<code>density(x, log = FALSE, with_params = list())</code> computes the (log-)density.</li>
<li>
<code>probability(q, lower.tail = TRUE, log.p = FALSE, with_params = list()</code> computes the (log-)cumulative distribution function or (log-)survival function.</li>
<li>
<code>hazard(x, log = FALSE. with_params = list())</code> computes the (log-)hazard function.</li>
<li>
<code>quantile(p, lower.tail = TRUE, log.p = FALSE, with_params = list())</code> computes upper or lower quantiles.</li>
<li>
<code>sample(n, with_params = list())</code> generates a random sample of size <code>n</code>. (<code>with_params</code> can contain length <code>n</code> vectors in this case).</li>
</ul>
</div>
<div class="section level4" number="2.2.3">
<h4 id="additional-functions">
<span class="header-section-number">2.2.3</span> Additional functions<a class="anchor" aria-label="anchor" href="#additional-functions"></a>
</h4>
<p>In addition to the basic functions, there are several supporting functions useful for, e.g., estimation of parameters.</p>
<ul>
<li>
<code>export_functions(name, with_params = list())</code> exports <code>{d,p,q,r}&lt;name&gt;</code> functions adhering to the common R convention for distribution functions.</li>
<li>
<code>get_type()</code> returns one of <code>"continuous"</code>, <code>"discrete"</code>, or <code>"mixed"</code> depending on whether the distribution family has a density with respect to the Lebesgue measure, the counting measure, or the sum of the Lebesgue measure with one or many point measures.</li>
<li>
<code>is_continuous()</code> and <code>is_discrete()</code> testing for the particular type.</li>
<li>
<code>has_capability(caps)</code> gives information on whether a specific implementation provides some or all of the features described.
Possible capabilities are <code>"sample"</code>, <code>"density"</code>, <code>"probability"</code>, <code>"quantile"</code>, <code>"diff_density"</code>, <code>"diff_probability"</code>, <code>"tf_logdensity"</code>, <code>"tf_logprobability"</code>.</li>
<li>
<code>require_capability(caps)</code> errors if the specified capabilities are not implemented for the family at hand.</li>
<li>
<code>is_discrete_at(x, with_params = list())</code> returns a logical vector indicating whether the distribution has a point mass at <code>x</code>.</li>
<li>
<code>is_in_support(x, with_params = list())</code> returns a logical vector indicating whether the distribution has any mass at <code>x</code>.</li>
</ul>
</div>
<div class="section level4" number="2.2.4">
<h4 id="performance-enhancements">
<span class="header-section-number">2.2.4</span> Performance enhancements<a class="anchor" aria-label="anchor" href="#performance-enhancements"></a>
</h4>
<p>When working with larger data or many calls to distribution functions, such as when performing a fit, it can be beneficial to just-in-time compile specialized functions that avoid overhead for dealing with the generic structure of distributions and their parametrization.
<code>Distribution</code>s offer a set of “compiler” functions that return simplified, faster, versions of the basic distribution functions, or that analytically compute gradients.
Those functions are not necessarily implemented for all <code>Distribution</code> classes, but will be automatically used by, e.g., <code><a href="../reference/fit_dist.html">fit_dist()</a></code> if useful.
The input structure for <code>param_matrix</code> can be obtained by <code>flatten_params_matrix(dist$get_placeholders())</code> where <code>dist</code> is the <code>Distribution</code> object in question.</p>
<ul>
<li>
<code>compile_density()</code> compiles a fast function with signature <code>(x, param_matrix, log = FALSE)</code> that will compute the density with fixed parameters hard-coded and taking the free parameters as a matrix with defined layout instead of a nested list.</li>
<li>
<code>compile_probability()</code> compiles a fast replacement for <code>probability</code> with signature <code>(q, param_matrix, lower.tail = TRUE, log.p = FALSE)</code>.</li>
<li>
<code>compile_probability_interval()</code> compiles a fast function with signature <code>(qmin, qmax, param_matrix, log.p = FALSE)</code> computing <span class="math inline">\(P(X \in [\mathtt{qmin}, \mathtt{qmax}])\)</span> or its logarithm efficiently. This expression is necessary for computing truncation probabilities.</li>
<li>
<code>compile_sample()</code> compiles a fast replacement for <code>sample</code> with signature <code>(n, param_matrix)</code>.</li>
<li>
<code>diff_density(x, log = FALSE, with_params = list())</code> computes the (log-)gradients of the density function with respect to free distribution family parameters, useful for maximum likelihood estimation.</li>
<li>
<code>diff_probability(q, lower.tail = TRUE, log.p = FALSE, with_params = list())</code> computes the (log-)gradients of the cumulative density function with respect to free distribution family parameters.
This is useful for conditional maximum likelihood estimation in the presence of random truncation or non-informative interval censoring.</li>
</ul>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_normal.html">dist_normal</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/flatten_params.html">flatten_params_matrix</a></span><span class="op">(</span><span class="va">dist</span><span class="op">$</span><span class="fu">get_placeholders</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##      mean sd</span></span>
<span><span class="co">## [1,]   NA NA</span></span></code></pre>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">denscmp</span> <span class="op">&lt;-</span> <span class="va">dist</span><span class="op">$</span><span class="fu">compile_density</span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/ns-load.html" class="external-link">requireNamespace</a></span><span class="op">(</span><span class="st">"bench"</span>, quietly <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">bench</span><span class="fu">::</span><span class="fu"><a href="http://bench.r-lib.org/reference/mark.html" class="external-link">mark</a></span><span class="op">(</span></span>
<span>    <span class="va">dist</span><span class="op">$</span><span class="fu">density</span><span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">:</span><span class="fl">2</span>, with_params <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">0.0</span>, sd <span class="op">=</span> <span class="fl">1.0</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    <span class="fu">denscmp</span><span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">:</span><span class="fl">2</span>, <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.0</span>, <span class="fl">1.0</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="fl">5L</span>, ncol <span class="op">=</span> <span class="fl">2L</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">dnorm</a></span><span class="op">(</span><span class="op">-</span><span class="fl">2</span><span class="op">:</span><span class="fl">2</span>, mean <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0.0</span>, <span class="fl">5L</span><span class="op">)</span>, sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1.0</span>, <span class="fl">5L</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<pre><code><span><span class="co">## <span style="color: #949494;"># A tibble: 3 × 6</span></span></span>
<span><span class="co">##   expression                            min  median `itr/sec` mem_alloc `gc/sec`</span></span>
<span><span class="co">##   <span style="color: #949494; font-style: italic;">&lt;bch:expr&gt;</span>                        <span style="color: #949494; font-style: italic;">&lt;bch:t&gt;</span> <span style="color: #949494; font-style: italic;">&lt;bch:t&gt;</span>     <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;bch:byt&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">## <span style="color: #BCBCBC;">1</span> dist$density(-2:2, with_params =… 26.68µs    29µs    <span style="text-decoration: underline;">33</span>911.        0B     17.0</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">2</span> denscmp(-2:2, matrix(c(0, 1), nr…  4.15µs  4.88µs   <span style="text-decoration: underline;">196</span>680.        0B     39.3</span></span>
<span><span class="co">## <span style="color: #BCBCBC;">3</span> dnorm(-2:2, mean = rep(0, 5L), s…   1.7µs  2.01µs   <span style="text-decoration: underline;">468</span>571.    2.58KB      0</span></span></code></pre>
</div>
<div class="section level4" number="2.2.5" short-title="tensorflow interface">
<h4 id="tensorflow-interface">
<span class="header-section-number">2.2.5</span> <strong>tensorflow</strong> interface<a class="anchor" aria-label="anchor" href="#tensorflow-interface"></a>
</h4>
<p>Use of distribution families from within <strong>tensorflow</strong> networks requires specialized implementations using the <strong>tensorflow</strong> APIs instead of regular <em>R</em> functions.
These are tailored to the needs of maximizing (conditional) likelihoods of weighted, censored and randomly truncated data.
Details on working with <strong>tensorflow</strong> can be found in Section <a href="#tensorflow">2.5</a>.</p>
<ul>
<li>
<code>tf_compile_params(input, name_prefix = "")</code> creates <strong>keras</strong> layers that take an <code>input</code> layer and transform it into a valid parametrization of the distribution family.</li>
<li>
<code>tf_is_discrete_at()</code> returns a <strong>tensorflow</strong>-ready version of <code>is_discrete_at()</code>.</li>
<li>
<code>tf_logdensity()</code> returns a <strong>tensorflow</strong>-ready version of <code>compile_density()</code> with implied <code>log = TRUE</code>.</li>
<li>
<code>tf_logprobability()</code> returns a <strong>tensorflow</strong>-ready version pf <code>compile_probability_interval()</code> with implied <code>log.p = TRUE</code>.</li>
<li>
<code>tf_make_constants()</code> creates a list of constant tensors for all fixed distribution family parameters.</li>
</ul>
</div>
</div>
<div class="section level3" number="2.3">
<h3 id="dist-definitions">
<span class="header-section-number">2.3</span> Special families<a class="anchor" aria-label="anchor" href="#dist-definitions"></a>
</h3>
<p>Some of the distribution families available in <strong>reservr</strong> have tailored algorithms for parameter estimation, or are not commonly known.
This section contains mathematical definitions of those function families.</p>
<div class="section level4" number="2.3.1">
<h4 id="dist-mixture">
<span class="header-section-number">2.3.1</span> Mixture distribution families<a class="anchor" aria-label="anchor" href="#dist-mixture"></a>
</h4>
<p>A mixture distribution family is defined by a fixed number <span class="math inline">\(k\)</span> of component families <span class="math inline">\(\{\mathcal{F}_i\}_{i = 1}^k\)</span> via the set of distributions</p>
<p><span class="math display">\[\begin{align*}
  \mathop{\mathrm{Mixture}}(\mathcal{F}_1, \ldots, \mathcal{F}_k) &amp; := \Bigl\{ F = \sum_{i = 1}^k p_i F_i \Bigm| F_i \in \mathcal{F}_i, p_i \in [0, 1], \sum_{i = 1}^k p_i = 1 \Bigr\}.
\end{align*}\]</span></p>
</div>
<div class="section level4" number="2.3.2">
<h4 id="dist-erlangmix">
<span class="header-section-number">2.3.2</span> Erlang mixture distribution families<a class="anchor" aria-label="anchor" href="#dist-erlangmix"></a>
</h4>
<p>An Erlang mixture distribution family is defined by its number of components <span class="math inline">\(k\)</span> as a mixture of Erlang distributions (Gamma distributions with integer shape parameter) with common scale parameter.
If <span class="math inline">\(\Gamma_{\alpha, \theta}\)</span> denotes a Gamma distribution with shape <span class="math inline">\(\alpha\)</span> and scale <span class="math inline">\(\theta\)</span>, the erlang mixture family with <span class="math inline">\(k\)</span> components can be defined as follows:</p>
<p><span class="math display">\[\begin{align*}
  \mathop{\mathrm{ErlangMixture}}(k) := \Bigl\{ F = \sum_{i = 1}^k p_i \Gamma_{\alpha_i, \theta} \Bigm|
   \alpha_i \in \mathbb{N}, \theta \in (0, \infty), p_i \in [0, 1], \sum_{i = 1}^k p_i = 1 \Bigr\}.
\end{align*}\]</span></p>
<p>Note that for <span class="math inline">\(k \to \infty\)</span>, Erlang mixtures are dense in the space of distributions on <span class="math inline">\((0, \infty)\)</span> with respect to weak convergence <span class="citation">(<a href="#ref-ll2012">Lee and Lin 2012</a>)</span>, making them a useful modeling choice for general positive continuous distributions. However, the tail index of all Erlang mixture distributions is always zero due to the exponential decay of Gamma densities.</p>
</div>
<div class="section level4" number="2.3.3">
<h4 id="dist-blended">
<span class="header-section-number">2.3.3</span> Blended distribution families<a class="anchor" aria-label="anchor" href="#dist-blended"></a>
</h4>
<p>A Blended distribution is defined in as follows: Given two underlying distributions <span class="math inline">\(P, Q\)</span> on <span class="math inline">\(\mathbb{R}\)</span> with cdfs <span class="math inline">\(F(\cdot)=P((-\infty, \cdot])\)</span> and <span class="math inline">\(G(\cdot)=Q((-\infty, \cdot])\)</span>, respectively, and parameters <span class="math inline">\(\kappa \in \mathbb{R}, \varepsilon \in (0, \infty), p_1, p_2 \in [0, 1], p_1 + p_2 = 1\)</span> such that <span class="math inline">\(F(\kappa) &gt; 0\)</span> and <span class="math inline">\(G(\kappa) &lt; 1\)</span>, we define the <em>Blended Distribution</em> <span class="math inline">\(B = \mathop{\mathrm{Blended}}(P, Q; p, \kappa, \varepsilon)\)</span> of <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> with blending interval <span class="math inline">\([\kappa - \varepsilon, \kappa + \varepsilon]\)</span> and mixture probabilities <span class="math inline">\(p\)</span> via its cdf
<span class="math inline">\(F_B\)</span>:</p>
<p><span class="math display">\[\begin{align*}
    p_{\kappa, \varepsilon}(x) &amp;=
    \begin{cases}
        x &amp; , x \in (-\infty, \kappa-\varepsilon],\\
        \tfrac12 (x + \kappa - \varepsilon) +
        \tfrac\varepsilon\pi \cos\Big( \frac{\pi (x - \kappa)}{2 \varepsilon} \Big) &amp;, x \in (\kappa-\varepsilon , \kappa+\varepsilon], \\
        \kappa &amp;, x  \in (\kappa +\varepsilon, \infty),
    \end{cases} \\
    \nonumber
    q_{\kappa, \varepsilon}(x) &amp; =
    \begin{cases}
        \kappa &amp; , x \in (-\infty, \kappa-\varepsilon],\\
        \tfrac12 (x + \kappa + \varepsilon) -
        \tfrac\varepsilon\pi \cos\Big( \frac{\pi (x - \kappa)}{2 \varepsilon} \Big) &amp;, x \in (\kappa-\varepsilon , \kappa+\varepsilon], \\
        x &amp;, x  \in (\kappa +\varepsilon, \infty),
    \end{cases} \\
    F_B(x) &amp; = p_1 \frac{F(p_{\kappa, \varepsilon}(x))}{F(\kappa)} + p_2 \frac{G(q_{\kappa, \varepsilon}(x)) - G(\kappa)}{1 - G(\kappa)}.
\end{align*}\]</span></p>
<p>The following illustration shows the components of a <span class="math inline">\(\mathrm{Blended}(\mathcal{N}(\mu = -1, \sigma = 1), \mathrm{Exp}(\lambda = 1); p = (0.5, 0.5), \kappa = 0, \varepsilon = 1)\)</span> distribution.</p>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dist1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_normal.html">dist_normal</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="op">-</span><span class="fl">1.0</span>, sd <span class="op">=</span> <span class="fl">1.0</span><span class="op">)</span></span>
<span><span class="va">dist2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_exponential.html">dist_exponential</a></span><span class="op">(</span>rate <span class="op">=</span> <span class="fl">1.0</span><span class="op">)</span></span>
<span><span class="va">distb</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_blended.html">dist_blended</a></span><span class="op">(</span></span>
<span>  dists <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">dist1</span>, <span class="va">dist2</span><span class="op">)</span>,</span>
<span>  breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fl">0.0</span><span class="op">)</span>,</span>
<span>  bandwidths <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fl">1.0</span><span class="op">)</span>,</span>
<span>  probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The transformation of the original component distributions (<span class="math inline">\(\mathcal{N}\)</span> and <span class="math inline">\(\mathrm{Exp}\)</span>) can be illustrated by first right- and left-truncating at <span class="math inline">\(\kappa = 0\)</span> respectively, and then applying the blending transformations <span class="math inline">\(p_{\kappa, \varepsilon}\)</span> and <span class="math inline">\(q_{\kappa, \varepsilon}\)</span>.
The latter distributions can be obtained in <strong>reservr</strong> by setting the probability weights of the blended distribution to <span class="math inline">\(p = (1, 0)\)</span> and <span class="math inline">\(p = (0, 1)\)</span> respectively.
Intermediate truncated distributions are obtained via <code>trunc_dist()</code>, with <span class="math inline">\(\kappa\)</span> as upper or lower bound respectively.</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">distt1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_trunc.html">dist_trunc</a></span><span class="op">(</span><span class="va">dist1</span>, min <span class="op">=</span> <span class="op">-</span><span class="cn">Inf</span>, max <span class="op">=</span> <span class="fl">0.0</span><span class="op">)</span></span>
<span><span class="va">distt2</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_trunc.html">dist_trunc</a></span><span class="op">(</span><span class="va">dist2</span>, min <span class="op">=</span> <span class="fl">0.0</span>, max <span class="op">=</span> <span class="cn">Inf</span><span class="op">)</span></span>
<span></span>
<span><span class="va">distb1</span> <span class="op">&lt;-</span> <span class="va">distb</span><span class="op">$</span><span class="fu">clone</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">distb1</span><span class="op">$</span><span class="va">default_params</span><span class="op">$</span><span class="va">probs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fl">1.0</span>, <span class="fl">0.0</span><span class="op">)</span></span>
<span><span class="va">distb2</span> <span class="op">&lt;-</span> <span class="va">distb</span><span class="op">$</span><span class="fu">clone</span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">distb2</span><span class="op">$</span><span class="va">default_params</span><span class="op">$</span><span class="va">probs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fl">0.0</span>, <span class="fl">1.0</span><span class="op">)</span></span></code></pre></div>
<p>We show the resulting density at each of the steps, and the final blended density obtained by weighting the blended component densities.</p>
<p><img src="jss_paper_files/figure-html/unnamed-chunk-14-1.png" width="672"><img src="jss_paper_files/figure-html/unnamed-chunk-14-2.png" width="672"></p>
<p>The definition of a blended distribution leads to the definition of a blended distribution family by allowing <span class="math inline">\(P, Q, \kappa\)</span> and <span class="math inline">\(\varepsilon\)</span> to vary:</p>
<p>Given two families <span class="math inline">\(\mathcal{F}, \mathcal{G}\)</span> of distributions on <span class="math inline">\(\mathbb{R}\)</span>, and parameters <span class="math inline">\(\kappa \in \mathbb{R}, \varepsilon \in (0, \infty)\)</span>, we define the <em>Blended Distribution family</em> as the family of Distributions
<!-- -->
<span class="math display">\[\begin{align*}
    \mathop{\mathrm{Blended}}(\mathcal{F}, \mathcal{G}; \kappa, \varepsilon) &amp; := \{ \mathop{\mathrm{Blended}}(P, Q ; p, \kappa, \varepsilon) \mid P \in \mathcal{F}, Q \in \mathcal{G}, p_1, p_2 \in [0, 1], p_1 + p_2 = 1 \}.
\end{align*}\]</span></p>
<p>Blended distribution families can be generalized to a number of components <span class="math inline">\(k\)</span> by letting <span class="math inline">\(\kappa\)</span> and <span class="math inline">\(\varepsilon\)</span> become vectors of dimension <span class="math inline">\(k - 1\)</span> such that <span class="math inline">\(\kappa_i + \varepsilon_i \le \kappa_{i + 1} - \varepsilon_{i + 1}\)</span> for <span class="math inline">\(i = 1, \ldots, k - 2\)</span>.
Compared to piecewise distribution families obtained by mixture of truncated distribution families with supports <span class="math inline">\((-\infty, \kappa]\)</span> and <span class="math inline">\([\kappa, \infty)\)</span> such as those commonly used for extreme value modelling, blended distribution families exhibit a continuous density within the blending region <span class="math inline">\((\kappa - \varepsilon, \kappa + \varepsilon)\)</span>.</p>
<p><strong>reservr</strong> provides an implementation via <code><a href="../reference/dist_blended.html">dist_blended()</a></code>, with limited support for more than two component families.</p>
</div>
<div class="section level4" number="2.3.4">
<h4 id="dist-bdegp">
<span class="header-section-number">2.3.4</span> The Blended Dirac Erlang Generalized Pareto distribution family<a class="anchor" aria-label="anchor" href="#dist-bdegp"></a>
</h4>
<p>Using the construction of a Blended distribution family, we can define the Blended Dirac Erlang Generalized Pareto (BDEGP) family as follows,
see .</p>
<p>Given parameters <span class="math inline">\(n \in \mathbb{N}, m \in \mathbb{N}, \kappa \in \mathbb{R}\)</span> and <span class="math inline">\(\varepsilon \in (0, \infty)\)</span>, we define the <em>Blended Dirac Erlang Generalized Pareto family</em> as the family of distributions</p>
<p><span class="math display">\[\begin{align*}
  \mathop{\mathrm{BDEGP}}(n, m, \kappa, \varepsilon) := &amp; \mathop{\mathrm{Mixture}}( \\
    &amp; \qquad \{\delta_0\}, \{\delta_1\}, \ldots, \{\delta_{n-1}\}, \\
    &amp; \qquad \mathop{\mathrm{Blended}}( \\
      &amp; \qquad\qquad \mathop{\mathrm{ErlangMixture}}(m), \\
      &amp; \qquad\qquad \{ \mathop{\mathrm{GPD}}(\kappa, \sigma, \xi) \mid \sigma \in (0, \infty), \xi \in [0, 1)) \}; \\
      &amp; \qquad\qquad \kappa, \varepsilon \\
    &amp; \qquad) \\
  &amp;),
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\delta_k\)</span> is the dirac distribution at <span class="math inline">\(k\)</span> and <span class="math inline">\(\mathrm{GPD}\)</span> is the generalized Pareto distribution.
Note the constraint on the tail index <span class="math inline">\(\xi \in [0, 1)\)</span>, guaranteeing finite expectation.</p>
<p>This distribution family has three features making it useful in modelling very general heavy-tailed distributions on <span class="math inline">\((0, \infty)\)</span>:</p>
<ol style="list-style-type: decimal">
<li>A maximally flexible lower tail</li>
<li>A flexible family of distributions for its body</li>
<li>A flexible tail index due to the generalized Pareto component</li>
</ol>
</div>
</div>
<div class="section level3" number="2.4">
<h3 id="fit-dist">
<span class="header-section-number">2.4</span> Methods of estimating distribution parameters<a class="anchor" aria-label="anchor" href="#fit-dist"></a>
</h3>
<p>This section describes the functions for the problem of estimating a parameter <span class="math inline">\(\theta \in \Theta\)</span> given a sample <span class="math inline">\(\mathfrak{I}\)</span> and a parameterized family <span class="math inline">\(\mathcal{F} = \{F_\theta \mid \theta \in \Theta\}\)</span>.
Sometimes, the conditional log-likelihood in <a href="#eq:cml-likelihood">(1.2)</a> can be directly maximized, yielding an estimate for <span class="math inline">\(\theta\)</span>.
This is the default behavior in <strong>reservr</strong> if no specialized estimation routine for the provided family <span class="math inline">\(\mathcal{F}_\theta\)</span> is defined.
Depending on whether there are box constraints, nonlinear constraints or no constraints on the parameter space <span class="math inline">\(\Theta\)</span>, different implementations of nonlinear optimization algorithms from <strong>nloptr</strong> <span class="citation">(<a href="#ref-nloptr">Johnson 2007</a>)</span>, in particular truncated Newton <span class="citation">(<a href="#ref-nloptr-tnewton">Dembo and Steihaug 1983</a>)</span> for unconstrained families, L-BFGS <span class="citation">(<a href="#ref-nloptr-lbfgs">Liu and Nocedal 1989</a>)</span> for box-constrained families and SLSQP <span class="citation">(<a href="#ref-nloptr-slsqp">Kraft 1994</a>)</span> for general constrained families are employed.</p>
<p>In addition to the naive direct optimization approach, some families lend themselves to specialized estimation algorithms which usually show faster convergence due to making use of special structures in the parameter space <span class="math inline">\(\Theta\)</span>.</p>
<p>Estimating distribution parameters from truncated observations is handled using the generic <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> method.
It delegates to <code><a href="../reference/fit_dist.html">fit_dist()</a></code>, which is also generic with signature:</p>
<ul>
<li>
<code>dist</code>: The distribution family to be fit</li>
<li>
<code>obs</code>: The <code>trunc_obs</code> object, or a vector of observed values</li>
<li>
<code>start</code>: Starting parameters, as a list compatible with <code>dist$get_placeholders()</code>.</li>
</ul>
<p>At the time of writing there are specialized algorithms for six types of families:</p>
<ol style="list-style-type: decimal">
<li>Blended distribution families </li>
<li>Erlang mixture distribution families </li>
<li>Generalized pareto distribution families with free lower bound <code>u</code> (estimated by the minimum of <code>xmin</code> over the sample)</li>
<li>Mixture distribution families </li>
<li>Translated distribution families with fixed <code>offset</code> and <code>multiplier</code> (transform the sample via <span class="math inline">\(\tfrac{\cdot-\text{offset}}{\text{multiplier}}\)</span> and fit the component distribution family to the transformed sample)</li>
<li>Uniform distribution families with free lower bound <code>min</code> or upper bound <code>max</code> (estimated by the minimum of <code>xmin</code>, for <code>min</code>, and the maximum of <code>xmax</code>, for <code>max</code>, over the sample)</li>
</ol>
<p>If not present, the <code>start</code> parameter is obtained via the <code><a href="../reference/fit_dist_start.html">fit_dist_start()</a></code> generic.
This generic implements a family specific method of generating valid starting values for all placeholder parameters.
A notable implementation is <code>fit_dist_start.ErlangMixtureDistribution()</code> for Erlang mixture distribution families.
If the shape parameters are free, there are different initialization strategies that can be chosen using additional arguments to <code><a href="../reference/fit_dist_start.html">fit_dist_start()</a></code>:</p>
<ul>
<li>
<code>init = "shapes"</code> paired with <code>shapes = c(...)</code> manually specifies starting shape parameters <span class="math inline">\(\alpha\)</span>
</li>
<li>
<code>init = "fan"</code> paired with <code>spread = d</code> uses <span class="math inline">\(\alpha = (1, 1 + d, \ldots, 1 + (k - 1) \cdot d)\)</span> with a default of <span class="math inline">\(d = 1\)</span> resulting in <span class="math inline">\(\alpha = (1, \ldots, k)\)</span>
</li>
<li>
<code>init = "kmeans"</code> uses 1-dimensional K-means based clustering of the sample observations such that each cluster corresponds to a unique shape</li>
<li>
<code>init = "cmm"</code> uses the centralized method of moments procedure described in </li>
</ul>
<p>Re-using <code>dist &lt;- dist_normal(sd = 1.0)</code> from above and the generated sample <code>obs</code>, we can fit the free parameter <code>mean</code>:</p>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_normal.html">dist_normal</a></span><span class="op">(</span>sd <span class="op">=</span> <span class="fl">1.0</span><span class="op">)</span></span>
<span><span class="va">the_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">dist</span>, <span class="va">obs</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">the_fit</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 3</span></span>
<span><span class="co">##  $ params:List of 1</span></span>
<span><span class="co">##   ..$ mean: num 0.0822</span></span>
<span><span class="co">##  $ opt   :List of 5</span></span>
<span><span class="co">##   ..$ par        : Named num 0.0822</span></span>
<span><span class="co">##   .. ..- attr(*, "names")= chr "mean"</span></span>
<span><span class="co">##   ..$ value      : num 341</span></span>
<span><span class="co">##   ..$ iter       : int 7</span></span>
<span><span class="co">##   ..$ convergence: int 1</span></span>
<span><span class="co">##   ..$ message    : chr "NLOPT_SUCCESS: Generic success return value."</span></span>
<span><span class="co">##  $ logLik:Class 'logLik' : -341 (df=1)</span></span></code></pre>
<p>Using the function <code><a href="../reference/plot_distributions.html">plot_distributions()</a></code> we can also assess the quality of the fit.</p>
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_distributions.html">plot_distributions</a></span><span class="op">(</span></span>
<span>  true <span class="op">=</span> <span class="va">dist</span>,</span>
<span>  fitted <span class="op">=</span> <span class="va">dist</span>,</span>
<span>  empirical <span class="op">=</span> <span class="fu"><a href="../reference/dist_empirical.html">dist_empirical</a></span><span class="op">(</span><span class="fl">0.5</span> <span class="op">*</span> <span class="op">(</span><span class="va">obs</span><span class="op">$</span><span class="va">xmin</span> <span class="op">+</span> <span class="va">obs</span><span class="op">$</span><span class="va">xmax</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  .x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>, <span class="fl">5</span>, length.out <span class="op">=</span> <span class="fl">201</span><span class="op">)</span>,</span>
<span>  plots <span class="op">=</span> <span class="st">"density"</span>,</span>
<span>  with_params <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    true <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>mean <span class="op">=</span> <span class="fl">0.0</span>, sd <span class="op">=</span> <span class="fl">1.0</span><span class="op">)</span>,</span>
<span>    fitted <span class="op">=</span> <span class="va">the_fit</span><span class="op">$</span><span class="va">params</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p><img src="jss_paper_files/figure-html/unnamed-chunk-16-1.png" width="672">
Here, the density labelled <code>empirical</code> corresponds to a kernel density estimate with automatic bandwidth selection.</p>
<p>We follow with an example of fitting an <span class="math inline">\(\mathrm{ErlangMixture}(3)\)</span> distribution family using various initialization strategies.
Note that both, <code>"kmeans"</code> and <code>"cmm"</code> use the random number generator for internal K-means clustering.
This necessitates setting a constant seed before running <code><a href="../reference/fit_dist_start.html">fit_dist_start()</a></code> and <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> to ensure the chosen starting parameters are the same for both calls.</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_erlangmix.html">dist_erlangmix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="cn">NULL</span>, <span class="cn">NULL</span>, <span class="cn">NULL</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">params</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  shapes <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fl">1L</span>, <span class="fl">4L</span>, <span class="fl">12L</span><span class="op">)</span>,</span>
<span>  scale <span class="op">=</span> <span class="fl">2.0</span>,</span>
<span>  probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fl">0.5</span>, <span class="fl">0.3</span>, <span class="fl">0.2</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1234</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">dist</span><span class="op">$</span><span class="fu">sample</span><span class="op">(</span><span class="fl">100L</span>, with_params <span class="op">=</span> <span class="va">params</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">32</span><span class="op">)</span></span>
<span><span class="va">init_true</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_dist_start.html">fit_dist_start</a></span><span class="op">(</span><span class="va">dist</span>, <span class="va">x</span>, init <span class="op">=</span> <span class="st">"shapes"</span>,</span>
<span>                            shapes <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">params</span><span class="op">$</span><span class="va">shapes</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">init_fan</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_dist_start.html">fit_dist_start</a></span><span class="op">(</span><span class="va">dist</span>, <span class="va">x</span>, init <span class="op">=</span> <span class="st">"fan"</span>, spread <span class="op">=</span> <span class="fl">3L</span><span class="op">)</span></span>
<span><span class="va">init_kmeans</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_dist_start.html">fit_dist_start</a></span><span class="op">(</span><span class="va">dist</span>, <span class="va">x</span>, init <span class="op">=</span> <span class="st">"kmeans"</span><span class="op">)</span></span>
<span><span class="va">init_cmm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/fit_dist_start.html">fit_dist_start</a></span><span class="op">(</span><span class="va">dist</span>, <span class="va">x</span>, init <span class="op">=</span> <span class="st">"cmm"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="../reference/flatten_params.html">flatten_params</a></span><span class="op">(</span><span class="va">init_true</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="../reference/flatten_params.html">flatten_params</a></span><span class="op">(</span><span class="va">init_fan</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="../reference/flatten_params.html">flatten_params</a></span><span class="op">(</span><span class="va">init_kmeans</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="../reference/flatten_params.html">flatten_params</a></span><span class="op">(</span><span class="va">init_cmm</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##      shapes[1] shapes[2] shapes[3]    scale probs[1] probs[2] probs[3]</span></span>
<span><span class="co">## [1,]         1         4        12 1.590800     0.43     0.33     0.24</span></span>
<span><span class="co">## [2,]         1         4         7 2.688103     0.55     0.32     0.13</span></span>
<span><span class="co">## [3,]         1         5        13 1.484960     0.43     0.36     0.21</span></span>
<span><span class="co">## [4,]         2        10        24 1.010531     0.56     0.27     0.17</span></span></code></pre>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">32</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">dist</span>, <span class="va">x</span>, init <span class="op">=</span> <span class="st">"shapes"</span>, shapes <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">params</span><span class="op">$</span><span class="va">shapes</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 4</span></span>
<span><span class="co">##  $ params     :List of 3</span></span>
<span><span class="co">##   ..$ probs :List of 3</span></span>
<span><span class="co">##   .. ..$ : num 0.43</span></span>
<span><span class="co">##   .. ..$ : num 0.33</span></span>
<span><span class="co">##   .. ..$ : num 0.24</span></span>
<span><span class="co">##   ..$ shapes:List of 3</span></span>
<span><span class="co">##   .. ..$ : num 1</span></span>
<span><span class="co">##   .. ..$ : num 4</span></span>
<span><span class="co">##   .. ..$ : num 13</span></span>
<span><span class="co">##   ..$ scale : num 1.59</span></span>
<span><span class="co">##  $ params_hist: list()</span></span>
<span><span class="co">##  $ iter       : int 1</span></span>
<span><span class="co">##  $ logLik     :Class 'logLik' : -290 (df=6)</span></span></code></pre>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">dist</span>, <span class="va">x</span>, init <span class="op">=</span> <span class="st">"fan"</span>, spread <span class="op">=</span> <span class="fl">3L</span><span class="op">)</span><span class="op">$</span><span class="va">logLik</span></span></code></pre></div>
<pre><code><span><span class="co">## 'log Lik.' -292.0026 (df=6)</span></span></code></pre>
<div class="sourceCode" id="cb58"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">dist</span>, <span class="va">x</span>, init <span class="op">=</span> <span class="st">"kmeans"</span><span class="op">)</span><span class="op">$</span><span class="va">logLik</span></span></code></pre></div>
<pre><code><span><span class="co">## 'log Lik.' -289.2834 (df=6)</span></span></code></pre>
<div class="sourceCode" id="cb60"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">dist</span>, <span class="va">x</span>, init <span class="op">=</span> <span class="st">"cmm"</span><span class="op">)</span><span class="op">$</span><span class="va">logLik</span></span></code></pre></div>
<pre><code><span><span class="co">## 'log Lik.' -293.1273 (df=6)</span></span></code></pre>
<p>It should be noted that the different initialization methods had a considerable impact on the outcome in the example due to the discrete nature of Erlang mixture distribution shape parameters and thus the combinatorial difficulty of picking optimal shapes <span class="math inline">\(\alpha\)</span>.
The <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> result for Erlang mixture distribution families contains an element named <code>"params_hist"</code>.
This can be populated by passing <code>trace = TRUE</code> to <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> and will record parameters after all ECME steps in the ECME-based estimation algorithms from and .
The element <code>"iter"</code> contains the number of full ECME-Iterations that were performed.</p>
</div>
<div class="section level3" number="2.5" short-title="distributional regression using tensorflow integration">
<h3 id="tensorflow">
<span class="header-section-number">2.5</span> Distributional regression using <strong>tensorflow</strong> integration<a class="anchor" aria-label="anchor" href="#tensorflow"></a>
</h3>
<p>The maximization problem <a href="#eq:cml-regression-likelihood">(1.3)</a> is delegated to <strong>tensorflow</strong>, which supplies ample stochastic optimization algorithms.
Functions in <strong>reservr</strong> are necessary to create a suitable output layer for <strong>tensorflow</strong> that maps onto <span class="math inline">\(\Theta\)</span> and to provide an implementation of the (negative) log-likelihood in <a href="#eq:cml-regression-likelihood">(1.3)</a> as a loss function.
These two tasks are combined in <code><a href="../reference/tf_compile_model.html">tf_compile_model()</a></code>.
The function returns an object of class <code>reservr_keras_model</code>, which can be used for the estimation procedure.</p>
<p>Given input layers <code>inputs</code> and an intermediate output layer <code>intermediate_output</code> as well as a family of distributions <code>dist</code>, the function</p>
<ul>
<li>Compiles the loss for <code>dist</code> defined by <a href="#eq:cml-regression-likelihood">(1.3)</a> as <span class="math inline">\(l(g) = -\tfrac{1}{\#(\mathfrak{I}_{\mathrm{reg}})} \ell(g|\mathfrak{I}_{\mathrm{reg}})\)</span>, optionally disabling <code>censoring</code> or <code>truncation</code> for efficiency.</li>
<li>Creates a list of final output layers mapping <code>intermediate_output</code> onto the parameter space <span class="math inline">\(\Theta\)</span> of <code>dist</code> using <code>Distribution$tf_compile_params()</code>.
This step adds additional degrees of freedom to the overall model, and the approach is described in </li>
<li>Runs <code><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">keras3::compile()</a></code> on the underlying <code>keras.src.models.model.Model</code>.</li>
</ul>
<p>The following example defines a linear model with homoskedasticity assumption and fits it using <span class="math inline">\(100\)</span> iterations of the Adam optimization algorithm <span class="citation">(<a href="#ref-Kingma2015">Kingma and Ba 2015</a>)</span>.
First, we simulate data <span class="math inline">\((Y,X)\)</span> from the model defined by <span class="math inline">\(X \sim \mathrm{Unif}(10,20)\)</span> and <span class="math inline">\(Y | X =x \sim \mathcal{N}(\mu = 2x, \sigma = 1)\)</span>.</p>
<div class="sourceCode" id="cb62"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1431L</span><span class="op">)</span></span>
<span><span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/set_random_seed.html" class="external-link">set_random_seed</a></span><span class="op">(</span><span class="fl">1432L</span><span class="op">)</span></span>
<span></span>
<span><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="fu">::</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span></span>
<span>  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fl">100</span>, min <span class="op">=</span> <span class="fl">10</span>, max <span class="op">=</span> <span class="fl">20</span><span class="op">)</span>,</span>
<span>  y <span class="op">=</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">x</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Next, we specify the distribution family <span class="math inline">\(\mathcal{F} = \{\mathcal{N}(\mu, \sigma = 1) | \mu\in\mathbb R\}\)</span>, incorporating the homoskedasticity assumption.</p>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_normal.html">dist_normal</a></span><span class="op">(</span>sd <span class="op">=</span> <span class="fl">1.0</span><span class="op">)</span></span></code></pre></div>
<p>Using <strong>keras</strong>, we define an empty neural network, just taking <span class="math inline">\(x\)</span> as an input and performing no transformation.</p>
<div class="sourceCode" id="cb64"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nnet_input</span> <span class="op">&lt;-</span> <span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/keras_input.html" class="external-link">keras_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fl">1L</span>, name <span class="op">=</span> <span class="st">"x_input"</span><span class="op">)</span></span>
<span><span class="va">nnet_output</span> <span class="op">&lt;-</span> <span class="va">nnet_input</span></span></code></pre></div>
<p>Then, <code><a href="../reference/tf_compile_model.html">tf_compile_model()</a></code> adapts the input layer to the free parameter space <span class="math inline">\(\Theta = \mathbb{R}\)</span>.
This introduces two parameters to the function family <span class="math inline">\(\mathcal{G}\)</span> and implies the functional relationship <span class="math inline">\(\mu = g(x) := \theta_1 \cdot x + \theta_0\)</span>.
Since our sample is fully observed, we disable censoring and truncation, leading to the simplified loss</p>
<p><span class="math display">\[\begin{align*}
  l(g) = -\tfrac{1}{100} \sum_{x, y} \log f_{g(x)}(y),
\end{align*}\]</span></p>
<p>where <span class="math inline">\(f_\mu(y)\)</span> is the density of <span class="math inline">\(\mathcal{N}(\mu=\mu, \sigma=1)\)</span> evaluated at <span class="math inline">\(y\)</span>.</p>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nnet</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tf_compile_model.html">tf_compile_model</a></span><span class="op">(</span></span>
<span>  inputs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">nnet_input</span><span class="op">)</span>,</span>
<span>  intermediate_output <span class="op">=</span> <span class="va">nnet_output</span>,</span>
<span>  dist <span class="op">=</span> <span class="va">dist</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/optimizer_adam.html" class="external-link">optimizer_adam</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span>,</span>
<span>  censoring <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  truncation <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span><span class="va">nnet</span><span class="op">$</span><span class="va">dist</span></span>
<span><span class="va">nnet</span><span class="op">$</span><span class="va">model</span></span></code></pre></div>
<p>The fit can now be performed, modifying the parameters (weights) of <code>nnet</code> in-place.
Note that the argument <code>y</code> of fit accepts a <code>trunc_obs</code> object.
In our example, the vector <code>y</code> is silently converted to an untruncated, uncensored <code>trunc_obs</code> object.
<code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> returns the <code>keras_training_history</code> of the underlying call to <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> on the <code>keras.src.models.model.Model</code>.</p>
<div class="sourceCode" id="cb66"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nnet_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span></span>
<span>  <span class="va">nnet</span>,</span>
<span>  x <span class="op">=</span> <span class="va">dataset</span><span class="op">$</span><span class="va">x</span>,</span>
<span>  y <span class="op">=</span> <span class="va">dataset</span><span class="op">$</span><span class="va">y</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">100L</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">100L</span>,</span>
<span>  shuffle <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The training history can be plotted, displaying the loss by epoch (black circles), and a blue smoothing line.</p>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Fix weird behavior of keras3</span></span>
<span><span class="va">nnet_fit</span><span class="op">$</span><span class="va">params</span><span class="op">$</span><span class="va">epochs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">nnet_fit</span><span class="op">$</span><span class="va">params</span><span class="op">$</span><span class="va">epochs</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">nnet_fit</span><span class="op">$</span><span class="va">metrics</span><span class="op">$</span><span class="va">loss</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">nnet_fit</span><span class="op">)</span></span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code> method of <code>reservr_keras_model</code> takes input tensors and returns the predicted distribution parameters as a list compatible with <code>dist$get_placeholders()</code>.
We can thus extract the only parameter <code>mean</code> and compare it to an OLS fit for the same dataset:</p>
<div class="sourceCode" id="cb68"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pred_params</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">nnet</span>, data <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html" class="external-link">as_tensor</a></span><span class="op">(</span><span class="va">dataset</span><span class="op">$</span><span class="va">x</span>, <span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/config_floatx.html" class="external-link">config_floatx</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">lm_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">x</span>, data <span class="op">=</span> <span class="va">dataset</span><span class="op">)</span></span>
<span></span>
<span><span class="va">dataset</span><span class="op">$</span><span class="va">y_pred</span> <span class="op">&lt;-</span> <span class="va">pred_params</span><span class="op">$</span><span class="va">mean</span></span>
<span><span class="va">dataset</span><span class="op">$</span><span class="va">y_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">lm_fit</span>, newdata <span class="op">=</span> <span class="va">dataset</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="va">dataset</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, y <span class="op">=</span> <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y_pred</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">y_lm</span><span class="op">)</span>, linetype <span class="op">=</span> <span class="fl">2L</span>, color <span class="op">=</span> <span class="st">"green"</span><span class="op">)</span></span></code></pre></div>
<p>Since a <code>reservr_keras_model</code> includes the underlying <code>keras.src.models.model.Model</code>, its parameters can also be extracted and compared to the OLS coefficients</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">coef_nnet</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rev.html" class="external-link">rev</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">nnet</span><span class="op">$</span><span class="va">model</span><span class="op">$</span><span class="fu">get_weights</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">coef_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/unname.html" class="external-link">unname</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">lm_fit</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">coef_nnet</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">coef_lm</span><span class="op">)</span></span></code></pre></div>
<p>We now discuss a more complex example involving censoring, using the right-censored <code>ovarian</code> dataset bundled with the <strong>survival</strong> package <span class="citation">(<a href="#ref-baseR">R Core Team 2023</a>)</span>.
Our goal is to predict the rate parameter of an exponential survival time distribution in cancer patients given four features <span class="math inline">\(X = (\mathtt{age}, \mathtt{resid.ds}, \mathtt{rx}, \mathtt{ecog.ps})\)</span> collected in the study.
The variables <span class="math inline">\(\mathtt{resid.ds}, \mathtt{rx}\)</span> and <span class="math inline">\(\mathtt{ecog.ps}\)</span> are indicator variables coded in <span class="math inline">\(\{1, 2\}\)</span>.
<span class="math inline">\(\mathtt{age}\)</span> is a continuous variable with values in <span class="math inline">\((38, 75)\)</span>.
Due to the different scale of the <span class="math inline">\(\mathtt{age}\)</span> variable, it is useful to separate it from the other variables in order to perform normalization.
Normalization using <code><a href="https://keras3.posit.co/reference/layer_normalization.html" class="external-link">keras3::layer_normalization()</a></code> transforms its input variables to zero mean and unit variance.
This step is not necessary for the categorical features.</p>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1219L</span><span class="op">)</span></span>
<span><span class="fu">tensorflow</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/set_random_seed.html" class="external-link">set_random_seed</a></span><span class="op">(</span><span class="fl">1219L</span><span class="op">)</span></span>
<span><span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/config_set_floatx.html" class="external-link">config_set_floatx</a></span><span class="op">(</span><span class="st">"float32"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">dist</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/dist_exponential.html">dist_exponential</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">ovarian</span> <span class="op">&lt;-</span> <span class="fu">survival</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/survival/man/ovarian.html" class="external-link">ovarian</a></span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  y <span class="op">=</span> <span class="fu"><a href="../reference/trunc_obs.html">trunc_obs</a></span><span class="op">(</span></span>
<span>    xmin <span class="op">=</span> <span class="va">ovarian</span><span class="op">$</span><span class="va">futime</span>,</span>
<span>    xmax <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html" class="external-link">ifelse</a></span><span class="op">(</span><span class="va">ovarian</span><span class="op">$</span><span class="va">fustat</span> <span class="op">==</span> <span class="fl">1</span>, <span class="va">ovarian</span><span class="op">$</span><span class="va">futime</span>, <span class="cn">Inf</span><span class="op">)</span></span>
<span>  <span class="op">)</span>,</span>
<span>  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    age <span class="op">=</span> <span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/as_tensor.html" class="external-link">as_tensor</a></span><span class="op">(</span><span class="va">ovarian</span><span class="op">$</span><span class="va">age</span>, <span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/config_floatx.html" class="external-link">config_floatx</a></span><span class="op">(</span><span class="op">)</span>, shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">ovarian</span><span class="op">)</span><span class="op">)</span>,</span>
<span>    flags <span class="op">=</span> <span class="fu"><a href="../reference/k_matrix.html">k_matrix</a></span><span class="op">(</span><span class="va">ovarian</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"resid.ds"</span>, <span class="st">"rx"</span>, <span class="st">"ecog.ps"</span><span class="op">)</span><span class="op">]</span> <span class="op">-</span> <span class="fl">1.0</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Next, we define the input layers and shapes, conforming to our input predictor list <code>dat$x</code>.</p>
<div class="sourceCode" id="cb71"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nnet_inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>  <span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/keras_input.html" class="external-link">keras_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fl">1L</span>, name <span class="op">=</span> <span class="st">"age"</span><span class="op">)</span>,</span>
<span>  <span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/keras_input.html" class="external-link">keras_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fl">3L</span>, name <span class="op">=</span> <span class="st">"flags"</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p><code>age</code> will be normalized and then concatenated to the other features, stored in <code>flags</code>, resulting in a 4-dimensional representation.
We then add two hidden ReLU-layers each with <span class="math inline">\(5\)</span> neurons to the network and compile the result, adapting the 5-dimensional hidden output to the parameter space <span class="math inline">\(\Theta = (0, \infty)\)</span> for the rate parameter of an exponential distribution.
This is accomplished using a dense layer with <span class="math inline">\(1\)</span> neuron and the <span class="math inline">\(\mathrm{softplus}\)</span> activation function.</p>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hidden1</span> <span class="op">&lt;-</span> <span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/layer_concatenate.html" class="external-link">layer_concatenate</a></span><span class="op">(</span></span>
<span>  <span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/layer_normalization.html" class="external-link">layer_normalization</a></span><span class="op">(</span><span class="va">nnet_inputs</span><span class="op">[[</span><span class="fl">1L</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>,</span>
<span>  <span class="va">nnet_inputs</span><span class="op">[[</span><span class="fl">2L</span><span class="op">]</span><span class="op">]</span></span>
<span><span class="op">)</span></span>
<span><span class="va">hidden2</span> <span class="op">&lt;-</span> <span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span></span>
<span>  <span class="va">hidden1</span>,</span>
<span>  units <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>  activation <span class="op">=</span> <span class="fu">keras3</span><span class="fu">::</span><span class="va"><a href="https://keras3.posit.co/reference/activation_relu.html" class="external-link">activation_relu</a></span></span>
<span><span class="op">)</span></span>
<span><span class="va">nnet_output</span> <span class="op">&lt;-</span> <span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/layer_dense.html" class="external-link">layer_dense</a></span><span class="op">(</span></span>
<span>  <span class="va">hidden2</span>,</span>
<span>  units <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>  activation <span class="op">=</span> <span class="fu">keras3</span><span class="fu">::</span><span class="va"><a href="https://keras3.posit.co/reference/activation_relu.html" class="external-link">activation_relu</a></span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">nnet</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/tf_compile_model.html">tf_compile_model</a></span><span class="op">(</span></span>
<span>  inputs <span class="op">=</span> <span class="va">nnet_inputs</span>,</span>
<span>  intermediate_output <span class="op">=</span> <span class="va">nnet_output</span>,</span>
<span>  dist <span class="op">=</span> <span class="va">dist</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="fu">keras3</span><span class="fu">::</span><span class="fu"><a href="https://keras3.posit.co/reference/optimizer_adam.html" class="external-link">optimizer_adam</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>,</span>
<span>  censoring <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  truncation <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span><span class="va">nnet</span><span class="op">$</span><span class="va">model</span></span></code></pre></div>
<p>For stability reasons, the default weight initialization is not optimal.
To circumvent this, we estimate a global exponential distribution fit on the observations and initialize the final layer weights such that the global fit is the initial prediction of the network.</p>
<div class="sourceCode" id="cb73"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">nnet</span>, <span class="va">dat</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">global_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">dist</span>, <span class="va">dat</span><span class="op">$</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/tf_initialise_model.html">tf_initialise_model</a></span><span class="op">(</span><span class="va">nnet</span>, params <span class="op">=</span> <span class="va">global_fit</span><span class="op">$</span><span class="va">params</span>, mode <span class="op">=</span> <span class="st">"zero"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">nnet</span>, <span class="va">dat</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Finally, we can train the network and visualize the predictions.</p>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">nnet_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span></span>
<span>  <span class="va">nnet</span>,</span>
<span>  x <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">x</span>,</span>
<span>  y <span class="op">=</span> <span class="va">dat</span><span class="op">$</span><span class="va">y</span>,</span>
<span>  epochs <span class="op">=</span> <span class="fl">100L</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">dat</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>,</span>
<span>  shuffle <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">nnet_fit</span><span class="op">$</span><span class="va">params</span><span class="op">$</span><span class="va">epochs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="va">nnet_fit</span><span class="op">$</span><span class="va">params</span><span class="op">$</span><span class="va">epochs</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">nnet_fit</span><span class="op">$</span><span class="va">metrics</span><span class="op">$</span><span class="va">loss</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">nnet_fit</span><span class="op">)</span></span>
<span></span>
<span><span class="va">ovarian</span><span class="op">$</span><span class="va">expected_lifetime</span> <span class="op">&lt;-</span> <span class="fl">1.0</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">nnet</span>, <span class="va">dat</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">$</span><span class="va">rate</span></span></code></pre></div>
<p>A plot of expected lifetime by <span class="math inline">\((\mathtt{age}, \mathtt{rx})\)</span> shows that the network learned longer expected lifetimes for lower <span class="math inline">\(\mathtt{age}\)</span> and for treatment group (<span class="math inline">\(\mathtt{rx}\)</span>) 2.
The global fit is included as a dashed blue line.</p>
<p>Individual predictions and observations can also be plotted on a subject level.</p>
</div>
</div>
<div class="section level2" number="3">
<h2 id="conclusion">
<span class="header-section-number">3</span> Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>We presented <strong>reservr</strong>, a package that supports distribution parameter estimation and distributional regression using <em>R</em>.
Both tasks are supported for samples with or without interval censoring and with or without random truncation, a more general form of truncation than what typical packages support.
The package includes facilities for (1) description of randomly truncated non-informatively interval censored samples, (2) definition of distribution families to consider, (3) global distribution parameter estimation under an i.i.d. assumption on the sample and (4) distributional regression - employing the <strong>tensorflow</strong> package for flexibility and speed.</p>
</div>
<div class="section level2">
<h2 id="acknowledgements">Acknowledgements<a class="anchor" aria-label="anchor" href="#acknowledgements"></a>
</h2>
<p>The Author would like to thank Axel Bücher for proofreading and valuable comments on an earlier version of this article.</p>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-tensorflow" class="csl-entry">
Abadi, Martín, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, et al. 2015. <span>“<span>TensorFlow</span>: Large-Scale Machine Learning on Heterogeneous Systems.”</span> <a href="https://www.tensorflow.org/" class="external-link">https://www.tensorflow.org/</a>.
</div>
<div id="ref-tensorflowR" class="csl-entry">
Allaire, JJ, and Yuan Tang. 2022. <em>Tensorflow: R Interface to ’TensorFlow’</em>. <a href="https://CRAN.R-project.org/package=tensorflow" class="external-link">https://CRAN.R-project.org/package=tensorflow</a>.
</div>
<div id="ref-R6" class="csl-entry">
Chang, Winston. 2021. <em>R6: Encapsulated Classes with Reference Semantics</em>. <a href="https://CRAN.R-project.org/package=R6" class="external-link">https://CRAN.R-project.org/package=R6</a>.
</div>
<div id="ref-kerasR" class="csl-entry">
Chollet, François, JJ Allaire, et al. 2017. <em>Keras: R Interface to ’Keras’</em>. GitHub. <a href="https://github.com/rstudio/keras3" class="external-link">https://github.com/rstudio/keras3</a>.
</div>
<div id="ref-fitdistrplus" class="csl-entry">
Delignette-Muller, Marie Laure, and Christophe Dutang. 2015. <span>“Fitdistrplus: An r Package for Fitting Distributions.”</span> <em>Journal of Statistical Software</em> 64 (4): 1–34. <a href="https://doi.org/10.18637/jss.v064.i04" class="external-link">https://doi.org/10.18637/jss.v064.i04</a>.
</div>
<div id="ref-nloptr-tnewton" class="csl-entry">
Dembo, Ron S., and Trond Steihaug. 1983. <span>“Truncated-<span>N</span>ewton Algorithms for Large-Scale Unconstrained Optimization.”</span> <em>Mathematical Programming</em> 26: 190–212. <a href="https://doi.org/10.1007/bf02592055" class="external-link">https://doi.org/10.1007/bf02592055</a>.
</div>
<div id="ref-DobsonBarnett2018" class="csl-entry">
Dobson, Annette J., and Adrian G. Barnett. 2018. <em>An Introduction to Generalized Linear Models</em>. 4th ed. CRC Press, Taylor &amp; Francis Group. <a href="https://doi.org/10.1201/9781315182780" class="external-link">https://doi.org/10.1201/9781315182780</a>.
</div>
<div id="ref-DoerreEmura2019" class="csl-entry">
Dörre, Achim, and Takeshi Emura. 2019. <em>Analysis of Doubly Truncated Data: An Introduction</em>. SpringerBriefs in Statistics. Springer Singapore. <a href="https://doi.org/10.1007/978-981-13-6241-5" class="external-link">https://doi.org/10.1007/978-981-13-6241-5</a>.
</div>
<div id="ref-flexsurv" class="csl-entry">
Jackson, Christopher. 2016. <span>“<span class="nocase">flexsurv</span>: A Platform for Parametric Survival Modeling in <span>R</span>.”</span> <em>Journal of Statistical Software</em> 70 (8): 1–33. <a href="https://doi.org/10.18637/jss.v070.i08" class="external-link">https://doi.org/10.18637/jss.v070.i08</a>.
</div>
<div id="ref-nloptr" class="csl-entry">
Johnson, Steven G. 2007. <span>“The <span>NLopt</span> Nonlinear-Optimization Package.”</span> <a href="https://github.com/stevengj/nlopt" class="external-link uri">https://github.com/stevengj/nlopt</a>.
</div>
<div id="ref-Kingma2015" class="csl-entry">
Kingma, Diederik P., and Jimmy Ba. 2015. <span>“Adam: A Method for Stochastic Optimization.”</span> In <em>Proceedings of the Third International Conference on Learning Representations</em>. ICLR’15.
</div>
<div id="ref-nloptr-slsqp" class="csl-entry">
Kraft, Dieter. 1994. <span>“Algorithm 733: <span>TOMP</span>–Fortran Modules for Optimal Control Calculations.”</span> <em><span>ACM</span> Transactions on Mathematical Software</em> 20: 262–81. <a href="https://doi.org/10.1145/192115.192124" class="external-link">https://doi.org/10.1145/192115.192124</a>.
</div>
<div id="ref-ll2012" class="csl-entry">
Lee, Simon C. K., and X. Sheldon Lin. 2012. <span>“Modeling Dependent Risks with Multivariate Erlang Mixtures.”</span> <em>ASTIN Bulletin</em> 42 (1): 153–80. <a href="https://doi.org/10.2143/AST.42.1.2160739" class="external-link">https://doi.org/10.2143/AST.42.1.2160739</a>.
</div>
<div id="ref-nloptr-lbfgs" class="csl-entry">
Liu, Dong C., and Jorge Nocedal. 1989. <span>“On the Limited Memory <span>BFGS</span> Method for Large Scale Optimization.”</span> <em>Mathematical Programming</em> 45: 503–28. <a href="https://doi.org/10.1007/bf01589116" class="external-link">https://doi.org/10.1007/bf01589116</a>.
</div>
<div id="ref-baseR" class="csl-entry">
R Core Team. 2023. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/" class="external-link">https://www.R-project.org/</a>.
</div>
<div id="ref-ROOPSD" class="csl-entry">
Robin, Yoann. 2022. <em>ROOPSD: R Object Oriented Programming for Statistical Distribution</em>. <a href="https://CRAN.R-project.org/package=ROOPSD" class="external-link">https://CRAN.R-project.org/package=ROOPSD</a>.
</div>
<div id="ref-deepregression" class="csl-entry">
Rügamer, David, Chris Kolb, Cornelius Fritz, Florian Pfisterer, Philipp Kopper, Bernd Bischl, Ruolin Shen, et al. 2023. <span>“Deepregression: A Flexible Neural Network Framework for Semi-Structured Deep Distributional Regression.”</span> <em>Journal of Statistical Software</em> 105 (2): 1–31. <a href="https://doi.org/10.18637/jss.v105.i02" class="external-link">https://doi.org/10.18637/jss.v105.i02</a>.
</div>
<div id="ref-GAMLSS" class="csl-entry">
Stasinopoulos, D. Mikis, and Robert A. Rigby. 2007. <span>“Generalized Additive Models for Location Scale and Shape (GAMLSS) in r.”</span> <em>Journal of Statistical Software</em> 23 (7): 1–46. <a href="https://doi.org/10.18637/jss.v023.i07" class="external-link">https://doi.org/10.18637/jss.v023.i07</a>.
</div>
<div id="ref-Sun2006" class="csl-entry">
Sun, Jianguo. 2006. <em>The Statistical Analysis of Interval-Censored Failure Time Data</em>. Statistics for Biology and Health. Springer, New York. <a href="https://doi.org/10.1007/0-387-37119-2" class="external-link">https://doi.org/10.1007/0-387-37119-2</a>.
</div>
<div id="ref-survival" class="csl-entry">
Therneau, Terry M. 2023. <em>A Package for Survival Analysis in r</em>. <a href="https://CRAN.R-project.org/package=survival" class="external-link">https://CRAN.R-project.org/package=survival</a>.
</div>
<div id="ref-MASS" class="csl-entry">
Venables, W. N., and B. D. Ripley. 2002. <em>Modern Applied Statistics with s</em>. Fourth. New York: Springer. <a href="https://www.stats.ox.ac.uk/pub/MASS4/" class="external-link">https://www.stats.ox.ac.uk/pub/MASS4/</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Alexander Rosenstock.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
